<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.1" />
<title>popnet.executors documentation</title>
<meta name="description" content="Functions to run numerical experiments …" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding-left:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        "SVG": {
            availableFonts: ["TeX"], 
            scale: 90,
            blacker: 0
        },
        MMLorHTML: {prefer: "HTML"},
    });
    MathJax.Hub.Register.StartupHook("SVG Jax Ready",function () {
      var VARIANT = MathJax.OutputJax["SVG"].FONTDATA.VARIANT;
      VARIANT["normal"].fonts.unshift("MathJax_SansSerif");
      VARIANT["bold"].fonts.unshift("MathJax_SansSerif-bold");
      VARIANT["italic"].fonts.unshift("MathJax_SansSerif-italic");
      VARIANT["-tex-mathit"].fonts.unshift("MathJax_SansSerif-italic");
    });
    MathJax.Hub.Register.StartupHook("SVG Jax Ready",function () {
      var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;
      VARIANT["normal"].fonts.unshift("MathJax_SansSerif");
      VARIANT["bold"].fonts.unshift("MathJax_SansSerif-bold");
      VARIANT["italic"].fonts.unshift("MathJax_SansSerif-italic");
      VARIANT["-tex-mathit"].fonts.unshift("MathJax_SansSerif-italic");
    });
</script>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_SVG"></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<style type="text/css">
    ul { 
        list-style-type: square; 
    }
    ul.hierarchy {
        list-style-type: none;
        padding-left: 2.5em;
        text-indent: -.8em;
    }
    ul.hierarchy > li:before {
        content: "\21B3 ";
    }
    ul.sidebar {
        border-left: 1px solid silver;
        margin-left: -.7em;
    }
    ol.references { 
        list-style-type: none; 
        margin-left: 0px; 
        padding-left: 2em; 
        position: relative; 
    }
    ol.references > li:before {
        content: "[" counter(enum, decimal) "]"; 
        left: 0.4em; 
        position: absolute; 
    }
    ol.references > li { 
        counter-increment: enum; 
    }
</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>popnet.executors</code></h1>
</header>
<section id="section-intro">
<p>Functions to run numerical experiments.</p>
<p>This module defines several classes dedicated to run numerical experiments using
the data structures defined in <code><a title="popnet.structures" href="structures.html">popnet.structures</a></code> and the dynamical systems
defined in <code><a title="popnet.systems" href="systems.html">popnet.systems</a></code>. Its methods allow both to</p>
<ul>
<li>Perform easily numerical integrations of several dynamical systems related
to the Wilson&ndash;Cowan model;</li>
<li>Perform simulations to study sample trajectories of a stochastic process
which is macroscopically approximated by the Wilson&ndash;Cowan model.</li>
</ul>
<p>The main classes defined in the module are briefly described in the
<a href="#classes-and-hierarchy">Classes And Hierarchy</a> section below. </p>
<h2 id="classes-and-hierarchy">Classes And Hierarchy</h2>
<p>The important classes of the module are summarized below. The indentation
follows the hierarchy. </p>
<ul class="hierarchy">
<li><code><a title="popnet.executors.Executor" href="#popnet.executors.Executor">Executor</a></code> : Abstract base class giving an interface to run numerical
experiments.<ul class="hierarchy sidebar">
<li><code><a title="popnet.executors.Integrator" href="#popnet.executors.Integrator">Integrator</a></code> : An interface to run numerical integrations.</li>
<li><code><a title="popnet.executors.Simulator" href="#popnet.executors.Simulator">Simulator</a></code> : An interface to run simulations of a stochastic process.<ul class="hierarchy sidebar">
<li><code><a title="popnet.executors.SimpleSimulator" href="#popnet.executors.SimpleSimulator">SimpleSimulator</a></code> : A simulator to run simulations one at a time.</li>
<li><code><a title="popnet.executors.ChainSimulator" href="#popnet.executors.ChainSimulator">ChainSimulator</a></code> : A simulator to run multiple simulations at once,
to compute statistics from the results.</li>
</ul>
</li>
</ul>
</li>
</ul>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Functions to run numerical experiments.

This module defines several classes dedicated to run numerical experiments using
the data structures defined in `popnet.structures` and the dynamical systems
defined in `popnet.systems`. Its methods allow both to

 - Perform easily numerical integrations of several dynamical systems related
   to the Wilson--Cowan model;
 - Perform simulations to study sample trajectories of a stochastic process
   which is macroscopically approximated by the Wilson--Cowan model.

The main classes defined in the module are briefly described in the
[Classes And Hierarchy](#classes-and-hierarchy) section below. 

Classes and hierarchy
---------------------
The important classes of the module are summarized below. The indentation
follows the hierarchy. 

 - `Executor` : Abstract base class giving an interface to run numerical
   experiments.
     - `Integrator` : An interface to run numerical integrations.
     - `Simulator` : An interface to run simulations of a stochastic process.
         - `SimpleSimulator` : A simulator to run simulations one at a time.
         - `ChainSimulator` : A simulator to run multiple simulations at once,
           to compute statistics from the results.

&#34;&#34;&#34;

import numpy as np
from scipy.integrate import ode
from tqdm import tqdm
from warnings import warn
from functools import singledispatch

from .exceptions import *
from . import _internals
from . import structures
from . import systems
from . import graphics


class Executor:
    &#34;&#34;&#34;Execute numerical experiments on a network.

    `Executor` is meant to perform numerical experiments to study the dynamics
    on a network split into populations. These experiments are intended to be
    carried out by subclasses of `Executor`.

     - To perform simulations of a stochastic process that rules the
       evolution of the network, use `Simulator`.
     - To perform numerical integrations of reduced dynamical systems
       describing the macroscopic behavior of the network, use `Integrator`.

    A reset of the executor is made at the end of the initialization, when
    setting the configuration.

    Parameters
    ----------
    config : popnet.structures.Configuration
        Configuration used for the experiments.

    Attributes
    ----------
    config : popnet.structures.Configuration
        Configuration used for the experiments. See `Executor.config`.
    times : array_like
        Time. See `Executor.times`.
    states : array_like
        State of the network with respect to time. See `Executor.states`.

    &#34;&#34;&#34;

    def __init__(self, config):
        self.config = config
        self._output_type = None

    @property
    def config(self):
        &#34;&#34;&#34;Configuration used with the executor.

        Configuration defining all parameters used by the executor. It must be
        a `popnet.structures.Configuration` instance, or a
        `popnet.structures.MicroConfiguration` instance if the network must
        have a microscopic structure. If it is set, the executor is reset with
        `Executor.reset`. It cannot be deleted.
        &#34;&#34;&#34;
        return self._config

    @config.setter
    def config(self, new_value):
        if not isinstance(new_value, structures.Configuration):
            raise TypeError(&#39;The configuration used with an executor must be a &#39;
                            &#39;\&#39;Configuration\&#39; instance.&#39;)
        self._config = new_value
        self.reset()

    @property
    def states(self):
        &#34;&#34;&#34;State of the network with respect to time.

        Macroscopic state of the network at each time step. It does not contain
        any relevant data at initialization or right after a reset, but it is
        updated during a call to `Executor.run`. It cannot be manually set nor
        deleted.
        &#34;&#34;&#34;
        return self._states

    @property
    def times(self):
        &#34;&#34;&#34;Time.

        At initialization or with a call to `Executor.reset`, it is set
        according to the executor&#39;s configuration `config`. Specifically, it
        is an array starting at `config.initial_time` and ending at
        `config.final_time`, with an interval of `config.delta` between time
        steps. It cannot be manually set nor deleted.
        &#34;&#34;&#34;
        return self._times

    @property
    def success(self):
        &#34;&#34;&#34;Indicator of success of a numerical experiment.

        Indicator of the success of a numerical experiment. It is set to `None`
        when the executor is reset, and then set to a boolean value after an
        experiment has been performed to indicate whether it was successful or
        not. It cannot be manually set nor deleted.
        &#34;&#34;&#34;
        return self._success

    def close(self):
        &#34;&#34;&#34;Delete all data attributes of the executor.&#34;&#34;&#34;
        del self._config
        del self._states
        del self._times
        del self._success

    def output(self, **kwargs):
        &#34;&#34;&#34;Get the output of the execution.

        Return the results of the numerical experiment.

        Parameters
        ----------
        **kwargs
            Keyword arguments to be passed to the output&#39;s class constructor.

        Returns
        -------
        popnet.graphics.Result
            The output of the experiment. The precise output type depends on the
            experiment executed; see the
            [summary](graphics.html#classes-and-hierarchy) of all
            `popnet.graphics.Result` subclasses for a quick reference giving
            the output type of each case.

        Raises
        ------
        popnet.exceptions.PopNetError
            If the numerical experiment has not been performed yet.
        &#34;&#34;&#34;
        self._check_if_run()
        if self._output_type is None:
            raise PopNetError(
                &#39;PopNet does not know how to output the results of this experi&#39;
                &#39;ment. It might be due to the use of the base class \&#39;Result\&#39; &#39;
                &#39;rather than its subclasses, or to the numerical integration &#39;
                &#39;of an unrecognized dynamical system. It might still be &#39;
                &#39;possible to save the results with Executor.save_output().&#39;)
        return self._output_type(self.config, self._output_states(), 
                                 self._output_times(), **kwargs)

    def reset(self):
        &#34;&#34;&#34;Reset the executor.
        
        Reset the executor to run it again. Sets `Executor.success` to `None`
        and resets `Executor.times` according to the configuration.
        &#34;&#34;&#34;
        self._success = None
        self._times = np.linspace(self.config.initial_time, 
                                  self.config.final_time, 
                                  1 + self.config.iterations)

    def run(self):
        &#34;&#34;&#34;Run the numerical experiment.
        
        This method is abstract and is implemented in subclasses.
        &#34;&#34;&#34;
        raise NotImplementedError(&#39;An executor must implement a \&#39;run\&#39; &#39;
                                  &#39;method.&#39;)

    def save_output(self, name=None, folder=None):
        &#34;&#34;&#34;Save the output of the experiment in a text file.

        Save the output of the numerical experiment in a text file, under the
        name *ID - name.txt*, where *ID* is the ID of the configuration used
        for the experiment and *name* is `name`.

        Parameters
        ----------
        name : str, optional
            Name to give to the saved output. Defaults to `None`, in which case
            it is replaced with a default based on the output class.
        folder : str, optional
            A folder in which the file is saved. If it does not exist in the
            current directory, it is created. Defaults to `None`, in which case
            the file is saved in the current directory.

        Returns
        -------
        name : str
            The name given to the saved output.

        Raises
        ------
        popnet.exceptions.PopNetError
            If the numerical experiment has not been performed yet.
        &#34;&#34;&#34;
        self._check_if_run()
        try:
            name = self._output_type._get_name(name)
        except AttributeError:
            name = &#39;Output&#39;
        filename = _internals._format_filename(folder, self.config.ID, name)
        _internals._make_sure_folder_exists(folder)
        L = self._state_length()
        header = &#39;&#39;.join([f&#39;{X:&lt;16}&#39; for X in self.config._variables[:L]])
        np.savetxt(filename, self._output_states(), fmt=&#39;%+.12f&#39;, header=header)
        return name

    def _check_if_run(self):
        &#34;&#34;&#34;Check if the executor has already run.&#34;&#34;&#34;
        if self.success is None:
            raise PopNetError(&#39;An executor has to run before the results are &#39;
                              &#39;output. Call Executor.run() first.&#39;)

    def _output_states(self):
        &#34;&#34;&#34;States array to output.&#34;&#34;&#34;
        return self.states

    def _output_times(self):
        &#34;&#34;&#34;Times array to output.&#34;&#34;&#34;
        return self.times

    def _state_length(self):
        &#34;&#34;&#34;Length of the macroscopic states.&#34;&#34;&#34;
        raise NotImplementedError(&#39;An executor must give its states\&#39; sizes.&#39;)


class Integrator(Executor):
    &#34;&#34;&#34;Numerical integrators for systems related to Wilson--Cowan&#39;s model.

    `Integrator` extends `Executor` to perform numerical integrations of
    dynamical systems related to the Wilson--Cowan model. Numerical
    integrations can either be performed with the class
    [ode](https://31c8.short.gy/scipy-integrate-ode) from SciPy&#39;s `integrate`
    module, or with a classical Runge--Kutta method.

    Parameters
    ----------
    system : popnet.systems.DynamicalSystem
        Sets the dynamical system to be integrated.

    Attributes
    ----------
    config : popnet.structures.Configuration
        Configuration used for the numerical integration. At initialization, it
        is automatically taken as that of `Integrator.system`. See
        `Integrator.config`.
    system : popnet.systems.DynamicalSystem
        Dynamical system used for the integration. See `Integrator.system`.
    times : array_like
        Time. See `Integrator.times`.
    states : array_like
        State of the network with respect to time. See `Integrator.states`.

    Raises
    ------
    TypeError
        If `system` is not a `popnet.systems.DynamicalSystem` instance.

    &#34;&#34;&#34;

    def __init__(self, system, **kwargs):
        if not isinstance(system, systems.DynamicalSystem):
            raise TypeError(&#39;The dynamical system associated with an integrator&#39;
                            &#39; must be a \&#39;DynamicalSystem\&#39; instance.&#39;)
        self._system = system
        super().__init__(system.config, **kwargs)
        try:
            output_type = OUTPUT_TYPES[type(self.system)]
        except KeyError:
            warn(&#39;The type of dynamical system you want to integrate is not &#39;
                 &#39;recognized by PopNet. The integration might be possible, &#39;
                 &#39;but it will not be possible to output the results with &#39;
                 &#39;Integrator.output().&#39;, category=PopNetWarning, stacklevel=2)
        else:
            self._output_type = output_type

    @property
    def system(self):
        &#34;&#34;&#34;Dynamical system used for the integration.

        The dynamical system used when performing numerical integrations. It
        is a `popnet.systems.DynamicalSystem` instance associated with the
        same configuration as the integrator. It is set at initialization,
        and afterwards it cannot be manually set nor deleted.
        &#34;&#34;&#34;
        return self._system

    def reset(self):
        &#34;&#34;&#34;Reset the integrator.

        Reset the integrator to run it again. It extends the base class method
        by also resetting `Integrator.states` and by setting the initial state
        to be used in the integration from the configuration.
        &#34;&#34;&#34;
        super().reset()
        self._states = np.zeros((len(self.times), self._state_length()))
        self.states[0] = self.config.initial_state[: self._state_length()]

    def run(self, task, time=&#39;forward&#39;, verbose=False, catch_escape=False,
            backend=&#39;vode&#39;, **kwargs):
        &#34;&#34;&#34;Run a numerical integration.

        Run a numerical integration of the dynamical system using either an
        [ode](https://31c8.short.gy/scipy-integrate-ode) instance from SciPy&#39;s
        `integrate` module, or a classical Runge--Kutta method.

        Parameters
        ----------
        task : {&#39;ode&#39;, &#39;runge-kutta&#39;}, optional
            Choose to integrate with SciPy&#39;s methods or with a classical
            Runge--Kutta method. Defaults to `&#39;ode&#39;`.
        time : {&#39;forward&#39;, &#39;backward&#39;}, optional
            Chooses if the intergration is performed forward of backward in
            time. If the integration is done backward in time, it is done from
            the initial time given by the configuration and for a total time
            interval of the same length as if it was done forward. Defaults to
            `&#39;forward&#39;`.
        verbose : bool, optional
            If `True`, a progression bar is printed to show how much of the
            integration has been performed. Defaults to `False`.
        catch_escape : bool, optional
            If `True`,  the integration stops as soon as a state component
            escapes the interval \\([-1, 1]\\), and the integration is
            considered to have failed. Defaults to `False`.
        backend : {&#39;vode&#39;, &#39;zvode&#39;, &#39;lsoda&#39;, &#39;dopri5&#39;, &#39;dop853&#39;}, optional
            Integrator used with SciPy&#39;s methods. Defaults to `&#39;vode&#39;`. It has
            no effect if `task` is not set to `&#39;ode&#39;`.
        **kwargs
            Keyword arguments to be passed to the `set_integrator` method of
            the `ode` solver. It has no effect if `task` is not set to `&#39;ode&#39;`.

        Warns
        -----
        popnet.exceptions.PopNetWarning
            If the integration fails.
        &#34;&#34;&#34;
        self._success = True
        if time == &#39;forward&#39;:
            def field(t, x): return self._field(t, x)
            def jac(t, x): return self._jac(t, x)
        elif time == &#39;backward&#39;:
            def field(t, x): 
                return - self._field(2 * self.config.initial_time - t, x)
            def jac(t, x): 
                return - self._jac(2 * self.config.initial_time - t, x)
        else:
            raise ValueError(f&#39;Unexpected value {time} for \&#39;time\&#39; keyword. &#39;
                             &#39;Valid values are \&#39;forward\&#39; and \&#39;backward\&#39;.&#39;)
        if verbose:
            def progress(rg): return tqdm(rg)
        else:
            def progress(rg): return rg
        if catch_escape:
            def has_escaped(state): return any(np.abs(state) &gt; 1)
        else:
            def has_escaped(state): return False
        if task == &#39;ode&#39;:
            self._run_ode(field, jac, progress, has_escaped, backend, **kwargs)
        elif task == &#39;runge-kutta&#39;:
            self._run_runge_kutta(field, progress, has_escaped)
        else:
            raise ValueError(f&#39;Unexpected task {task} for Integrator.run(). &#39;
                             &#39;Valid values are \&#39;ode\&#39;  and \&#39;runge-kutta\&#39;.&#39;)
        if time == &#39;backward&#39;:
            self._times = np.flip(2 * self.config.initial_time - self.times)
            self._states = np.flip(self.states, axis=0)
        if not self.success:
            warn(f&#39;Integration failed with configuration {self.config.ID}.&#39;,
                 category=PopNetWarning, stacklevel=2)

    def _field(self, t, Y):
        &#34;&#34;&#34;Vector field.

        Vector field corresponding to the studied dynamical system.

        Parameters
        ----------
        t : float
            Current time.
        Y : array_like
            Current state of the network.

        Returns
        -------
        array_like
            Gradient of the vector field evaluated at time `t` and state `Y`.
        &#34;&#34;&#34;
        return self.system.vector_field(Y)

    def _jac(self, t, Y):
        &#34;&#34;&#34;Jacobian of the `_field` method.

        Jacobian of the vector field corresponding to the studied dynamical
        system. It does not have to be implemented by subclasses.

        Parameters
        ----------
        t : float
            Current time.
        Y : array_like
            Current state of the network.

        Returns
        -------
        array_like
            Jacobian of the vector field evaluated at time `t` and state `Y`.
        &#34;&#34;&#34;
        return self.system.jac(Y)

    def _output_states(self):
        &#34;&#34;&#34;States array to output.&#34;&#34;&#34;
        if isinstance(self.system, systems.WilsonCowanSystem):
            p = len(self.config.network.populations)
            output_states = np.zeros((len(self.times), 2*p))
            output_states[:,:p] = self.states
            for J, popJ in enumerate(self.config.network.populations):
                output_states[:,p+J] = popJ.beta / popJ.gamma * self.states[:,J]
            return output_states
        return super()._output_states()

    def _run_ode(self, field, jac, progress, has_escaped, backend, **kwargs):
        &#34;&#34;&#34;Run a numerical integration with `scipy.integrate.ode`.&#34;&#34;&#34;
        try:
            jac(0, self.states[0])
        except NotImplementedError:
            solver = ode(field)
        else:
            solver = ode(field, jac)
        solver.set_integrator(backend, **kwargs)
        solver.set_initial_value(self.states[0])
        for j in progress(range(1, len(self.times))):
            self.states[j] = solver.integrate(solver.t+self.config.delta)[:]
            if not solver.successful() or has_escaped(self.states[j]):
                self._success = False
                break

    def _run_runge_kutta(self, field, progress, has_escaped):
        &#34;&#34;&#34;Run a numerical integration with a classical Runge--Kutta method.&#34;&#34;&#34;
        for j in progress(range(1, len(self.times))):
            k1 = field(0, self.states[j-1])
            k2 = field(0, self.states[j-1] + self.config.delta * k1 / 2)
            k3 = field(0, self.states[j-1] + self.config.delta * k2 / 2)
            k4 = field(0, self.states[j-1] + self.config.delta * k3)
            slope = (k1 + 2*k2 + 2*k3 + k4) / 6
            self.states[j] = self.states[j-1] + self.config.delta * slope
            if has_escaped(self.states[j]):
                self._success = False
                break

    def _state_length(self):
        &#34;&#34;&#34;Length of the macroscopic states.&#34;&#34;&#34;
        return self.system.dim


class LyapunovExponentsIntegrator(Integrator):
    &#34;&#34;&#34;Interface to estimate Lyapunov exponents of dynamical systems.

    This class extends `Integrator` to compute the Lyapunov exponents along the
    integrated solution when calling `LyapunovExponentsIntegrator.run`. For
    this to work, the dynamical system must have a Jacobian matrix implemented,
    and an error is raised at initialization if no Jacobian matrix is defined.

    The Lyapunov exponents are computed using the discrete QR method described
    by Dieci et al. in [1].

    References
    ----------
     1. Dieci, Luca, Robert D. Russell, and Erik S. Van Vleck. “On the
        Computation of Lyapunov Exponents for Continuous Dynamical Systems.”
        *SIAM Journal on Numerical Analysis* **34** (1), 402--423 (1997). doi:
        [10.1137/S0036142993247311](https://doi.org/10.1137/S0036142993247311)

    &#34;&#34;&#34;

    def __init__(self, system, **kwargs):
        super().__init__(system, **kwargs)
        try:
            self.system.jac
        except NotImplementedError as error:
            raise ValueError(&#39;The system must have a Jacobian matrix &#39;
                             &#39;implemented.&#39;) from error
        self._dim = self.system.dim

    @property
    def exponents(self):
        &#34;&#34;&#34;Lyapunov exponents.

        Estimates of the Lyapunov exponents of the dynamical system along the
        integrated solution, once they have been computed. It is automatically
        set during a call to `LyapunovExponentsIntegrator.run`. It cannot be
        manually set nor deleted.
        &#34;&#34;&#34;
        return self._exponents

    def close(self):
        &#34;&#34;&#34;Delete all data attributes of the integrator.&#34;&#34;&#34;
        super().close()
        del self._uptri_diag
        del self._exponents

    def output(self, **kwargs):
        &#34;&#34;&#34;Get the output of the integration.

        Return the results of the numerical integration. It extends the base
        class method by returning the Lyapunov exponents as well as the
        solution.

        Parameters
        ----------
        **kwargs
            Keyword arguments to be passed to the output&#39;s class constructor.

        Returns
        -------
        popnet.graphics.Result
            The output of the integration. The precise output type depends on
            the dynamical system that has been integrated; see the
            [summary](graphics.html#classes-and-hierarchy) of all
            `popnet.graphics.Result` subclasses for a quick reference giving
            the output type of each case.
        array_like
            The Lyapunov exponents.

        Raises
        ------
        popnet.exceptions.PopNetError
            If the numerical integration has not been performed yet.
        &#34;&#34;&#34;
        return super().output(), self.exponents

    def reset(self):
        &#34;&#34;&#34;Reset the integrator.
        
        Reset the integrator to run it again. It extends the base class method
        by also resetting `LyapunovExponentsIntegrator.exponents`.
        &#34;&#34;&#34;
        super().reset()
        self._exponents = None
        self._uptri_diag = np.zeros((len(self.times), self._state_length()))
        self._uptri_diag[0] = np.ones(self._state_length())

    def run(self, time=&#39;forward&#39;, verbose=False, catch_escape=False,
            backend=&#39;vode&#39;, **kwargs):
        &#34;&#34;&#34;Run a numerical integration.

        This method extends the base class method to be able to compute
        Lyapunov exponents. The interface is the same as that of the base
        class method, except that here the integration is only implemented
        using SciPy&#39;s methods.

        See Also
        --------
        Integrator.run
        &#34;&#34;&#34;
        super().run(&#39;ode&#39;, time=time, verbose=verbose,
                    catch_escape=catch_escape, backend=backend, **kwargs)
        logs = np.log(np.abs(self._uptri_diag))
        self._exponents = np.sum(logs, axis=0) / self.times[-1]

    def _field(self, t, Z):
        &#34;&#34;&#34;Vector field.

        Vector field of the differential equation used to estimate Lyapunov
        exponents. See the [Notes](#notes) section below for details.

        Parameters
        ----------
        t : float
            Current time.
        Z : array_like
            Current state of the system.

        Returns
        -------
        array_like
            Gradient of the vectori field evaluated at time `t` and state `Z`.

        Notes
        -----
        This vector field is defined from the vector field *f* of the dynamical
        system `LyapunovExponentsIntegrator.system`. Indeed, to estimate the
        Lyapunov exponents, two differential equations are solved
        simultaneously, namely *x&#39; = f(x)* and *Y&#39; = Df(x(t))Y*, where *Y*
        is a square matrix. The present vector field is simply the
        concatenation of *f* with a flattenned version of its Jacobian matrix.
        &#34;&#34;&#34;
        x = Z[:self._dim]
        Y = np.reshape(Z[self._dim:], (self._dim, self._dim))
        f = np.zeros(self._dim * (self._dim + 1))
        f[:self._dim] = self.system.vector_field(x)
        f[self._dim:] = np.matmul(self.system.jac(x), Y).flatten()
        return f

    def _run_ode(self, field, jac, progress, has_escaped, backend, **kwargs):
        &#34;&#34;&#34;Run a numerical integration with `scipy.integrate.ode`.

        This method overrides the base class method to be able to compute
        Lyapunov exponents.
        &#34;&#34;&#34;
        initial_value = np.concatenate((self.states[0],
                                        np.identity(self._dim).flatten()))
        solver = ode(field)
        solver.set_integrator(backend, **kwargs)
        solver.set_initial_value(initial_value, 0)
        for j in progress(range(len(self.times[:-1]))):
            state = solver.integrate(solver.t + self.config.delta)
            if not solver.successful():
                self._success = False
                break
            self.states[j+1] = state[:self._dim]
            Y = np.reshape(state[self._dim:], (self._dim, self._dim))
            q, r = np.linalg.qr(Y)
            self._uptri_diag[j+1] = np.diag(r)
            initial_value = np.concatenate((state[:self._dim], q.flatten()))
            solver.set_initial_value(initial_value, self.times[j+1])


class Simulator(Executor):
    &#34;&#34;&#34;Numerical simulator of the stochastic process on a network.

    `Simulator` extends `Executor` to perform numerical simulations of
    stochastic processes on a network that can be macroscopically approximated
    by the Wilson--Cowan model.

    Parameters
    ----------
    config : popnet.structures.MicroConfiguration
        Sets the configuration used for simulations.
    act : {&#39;step&#39;, &#39;sigmoid&#39;}, optional
        Sets the shape of the activation rate of a neuron. Defaults to `step`.

    Attributes
    ----------
    config : popnet.structures.MicroConfiguration
        Configuration used for the simulations. See `Simulator.config`.
    states, times : array_like
        Macroscopic state of the network with respect to time. See
        `Simulator.states` and `Simulator.times`.
    micro_states, transition_times : array_like
        Microscopic state of the network with respect to time. See
        `Simulator.micro_states` and `Simulator.transition_times`.
    activation_rates : list
        Activation rates of the neurons of the network. See
        `Simulator.activation_rates`.
    activation_rates_shape : {&#39;step&#39;, &#39;sigmoid&#39;}
        Describes the shape of the activation rate of neurons of the network.
        See `Simulator.activation_rates_shape`.

    &#34;&#34;&#34;

    def __init__(self, config, act=&#39;step&#39;, **kwargs):
        self.activation_rates_shape = act
        super().__init__(config, **kwargs)
        try:
            output_type = OUTPUT_TYPES[type(self)]
        except KeyError:
            warn(&#39;The type of simulator you want to run is not recognized by &#39;
                 &#39;PopNet. The simulation might be possible if a \&#39;run\&#39; method &#39;
                 &#39;is implemented, but it will not be possible to output the &#39;
                 &#39;results with Simulator.output().&#39;, category=PopNetWarning,
                 stacklevel=2)
        else:
            self._output_type = output_type

    @Executor.config.setter
    def config(self, new_value):
        if not isinstance(new_value, structures.MicroConfiguration):
            raise TypeError(&#39;The configuration used with a simulator must be a &#39;
                            &#39;\&#39;MicroConfiguration\&#39; instance.&#39;)
        self._config = new_value
        self.reset()

    @property
    def micro_states(self):
        &#34;&#34;&#34;Microscopic state of the network with respect to time.

        Microscopic state of the network at each time step in
        `Simulator.transition_times`. It does not contain any relevant data at
        initialization or right after a reset, but it is updated during a call
        to `Simulator.run`. It cannot be manually set nor deleted.
        &#34;&#34;&#34;
        return self._micro_states

    @property
    def transition_times(self):
        &#34;&#34;&#34;Time.

        Times at which transitions have occurred for a given trajectory. Unlike
        `Simulator.times`, it is not set according to the configuration used,
        but rather updated stochastically during a call to `Simulator.run`. It
        does not contain any relevant data at initialization or right after a
        reset. It cannot be manually set nor deleted.
        &#34;&#34;&#34;
        return self._transition_times

    @property
    def activation_rates(self):
        &#34;&#34;&#34;Activation rates of the neurons.

        List of functions representing the activation rates of the network&#39;s
        neurons. `activation_rates[j](x)` gives the activation rate of the
        *j*th neuron of the network if the state of the whole network is `x`.
        It cannot be manually set nor deleted.
        &#34;&#34;&#34;
        return self._activation_rates

    @property
    def activation_rates_shape(self):
        &#34;&#34;&#34;Shape of the activation rates.

        Shape of the activation rate of a single neuron of the network as a
        function of its input. The only valid values are:

         - `&#39;step&#39;`. In that case, a neuron&#39;s activation rate is a step
           function going from zero to `popnet.structures.MicroNetwork.alpha`
           at its threshold `popnet.structures.MicroNetwork.theta`.
         - `&#39;sigmoid&#39;`. In that case, a neuron&#39;s activation rate is the
           logistic function `popnet.structures.Population.F` of the population
           to which it belongs.

        It can only be set to one of the above values, and it cannot be
        manually deleted.

        !!! note
            After initialization, a change in the value of this property will
            only have an effect after a reset of the simulator with
            `Simulator.reset`.
        &#34;&#34;&#34;
        return self._activation_rates_shape

    @activation_rates_shape.setter
    def activation_rates_shape(self, new_value):
        valid_values = [&#39;step&#39;, &#39;sigmoid&#39;]
        if new_value not in valid_values:
            raise ValueError(f&#39;Unexpected value {new_value} for the shape of &#39;
                             &#39;the activation rates. Valid values are &#39;
                             f&#39;{valid_values}.&#39;)
        self._activation_rates_shape = new_value

    def calcium_output(self, indices=None, growth_rate=None, decay_rate=None):
        &#34;&#34;&#34;Get the calcium concentration in neural cells.

        Get the concentration of calcium in neural cells with respect to time. 

        Parameters
        ----------
        indices : int or array_like, optional
            Indices of neurons for which to get the calcium concentration.
            Defaults to `None`, in which case the calcium concentration is given
            for every neuron of the network.
        growth_rate : float, optional
            Initial growth rate of the calcium concentration. It must be
            positive. Defaults to `None`, in which case it is replaced with the
            inverse of the configuration&#39;s time step
            `popnet.structures.Configuration.delta`.
        decay_rate : float, optional
            Decay rate of the calcium concentration. It must be positive, and it
            should be much smaller than the initial growth rate. Defaults to
            `None`, in which case it is replaced with five percent of the
            initial growth rate.

        Returns
        -------
        array_like
            Calcium concentration with respect to time for every requested
            neuron, with neurons along the first axis and time along the second.
            If a single neuron was requested, it is one-dimensional.

        Raises
        ------
        ValueError
            If `indices` is not a valid list of indices for neurons of the
            network.
        &#34;&#34;&#34;
        if growth_rate is None:
            growth_rate = 1 / self.config.delta
        if decay_rate is None:
            decay_rate = .05 * growth_rate
        if isinstance(indices, int):
            return self._get_calcium_output(indices, growth_rate, decay_rate)
        valid_indices = np.arange(self.config.network.size())
        if indices is None:
            indices = valid_indices
        try:
            valid_indices[indices]
        except IndexError as error:
            raise ValueError(f&#39;{indices} is not a valid list of indices for &#39;
                             &#39;neurons of the network.&#39;) from error
        calcium = np.zeros((N := len(indices), len(self.transition_times)))
        for j in range(N):
            calcium[j,:] = self._get_calcium_output(j, growth_rate, decay_rate)
        return calcium

    def close(self):
        &#34;&#34;&#34;Delete all data attributes of the simulator.&#34;&#34;&#34;
        super().close()
        del self._micro_states
        del self._transition_times

    def micro_output(self, fmt=&#39;ternary&#39;):
        &#34;&#34;&#34;Get the simulation&#39;s microscopic output.
        
        Get the microscopic state of the network with respect to time after
        a simulation was performed.

        Parameters
        ----------
        fmt : {&#39;binary&#39;, &#39;ternary&#39;, &#39;calcium&#39;}, optional
            Format of the neurons&#39; states. If `&#39;ternary&#39;`, a neuron&#39;s state can
            take the values `1`, `1j` or `0`, associated with the *active*,
            *refractory* and *sensitive* states respectively. If `&#39;binary&#39;`, a
            neuron&#39;s state can take the values `1` or `0`, where `1` is still
            associated with the active state, but `0` is rather associated with
            any non-active state (sensitive or refractory). If `&#39;calcium&#39;`,
            the returned output is the default given by
            `Simulator.calcium_output`. Defaults to `&#39;ternary&#39;`.

        Returns
        -------
        array_like
            Microscopic state of the network with respect to time.

        Raises
        ------
        ValueError
            If `fmt` is passed an unexpected value.
        &#34;&#34;&#34;
        self._check_if_run()
        if fmt == &#39;ternary&#39;:
            return self.micro_states
        if fmt == &#39;binary&#39;:
            return np.real(self.micro_states)
        if fmt == &#39;calcium&#39;:
            return self.calcium_output()
        raise ValueError(f&#39;Unexpected format {fmt} for microscopic states. Valid&#39;
                         &#39; values are \&#39;ternary\&#39;, \&#39;binary\&#39; and \&#39;calcium\&#39;.&#39;)

    def reset(self):
        &#34;&#34;&#34;Reset the simulator.

        Reset the simulator to run it again. It extends the base class method
        by also resetting the arrays `Simulator.states`,
        `Simulator.micro_states` and `Simulator.transition_times`, by
        resetting the activation rate functions, and by resetting the
        microscopic initial state to be used in the simulation from the
        configuration.
        &#34;&#34;&#34;
        super().reset()
        self._states = None
        self._transition_times = [self.config.initial_time]
        self._micro_states = [self.config.micro_initial_state.copy()]
        self._reset_activation_rates()

    def single_run(self, rng, do_step, iterate):
        &#34;&#34;&#34;Run a single simulation.

        Run a simulation to obtain a possible trajectory of the stochastic
        process which describes the evolution of the network. To obtain this
        trajectory, the Doob--Gillespie algorithm is used either with the
        direct method or with the first reaction method. See the
        [Notes](#simulator-single-run-notes) section below for more details
        about the algorithm.

        !!! note
            The recommended way to perform simulations of the stochastic process
            is *not* to use this method, but rather to use `SimpleSimulator.run`
            or `ChainSimulator.run`, which both use it internally.

        Parameters
        ----------
        rng : numpy.random.Generator
            A random number generator.
        do_step : callable
            Dictates how to do the Monte Carlo step of the Doob--Gillespie
            algorithm. It is a function to be passed to `iterate`. It expects
            as inputs, in order: `rng`, the current time `t`, an array of the
            next possible network states, and an array of the corresponding
            transition rates. It should return the index of the next network
            state and the time interval between `t` and the next transition.
        iterate : callable
            Dictates how a complete iteration of the simulation is performed.
            This includes the Monte Carlo step as well as all other tasks that
            should be done at each time step. It expects as inputs, in order:
            `do_step`, `rng`, `t` and `x`, where `t` and `x` are the current
            time and network state. It should return the next time and network
            state.

        Notes {#simulator-single-run-notes}
        -----
        From the microscopic point of view, the evolution of the state of the
        whole network is described by a stochastic process. The simulation run
        by this method outputs a possible trajectory of this stochastic process,
        using the Doob--Gillespie algorithm, based on results of Doob [1,2] and
        popularized by Gillespie in [3]. To pass from a state to another, the
        idea is first to find all of the states to which the network can go
        from the current one, with the corresponding transition rates. This
        information is in fact sufficient to determine the distribution of the
        time at which the next transition occurs and which one will occur.

        In [3], Gillespie introduces two methods, called the *direct* and
        *first reaction* methods respectively, to choose the time interval until
        the next transition and the next state of the system.

         - **Direct method.** First, the total transition rate out of the
           current state is computed, and a time interval until the next
           transition is taken randomly knowing that it is exponentially
           distributed with parameter equal to this total out rate. Then a next
           state is chosen randomly knowing that the probability of going to a
           given other state is proportional to the corresponding transition
           rate.

         - **First reaction method.** For every possible next state, a time at
           which the corresponding transition could occur is randomly generated,
           knowing that this time is exponentially distributed with parameter
           equal to the transition rate. The transition that should occur first
           is chosen, and the state is updated accordingly.

        References
        ----------
         1. Doob, J. L. “Topics in the Theory of Markoff Chains.” *Transactions
            of the American Mathematical Society* **52**, 37--64 (1942).
            doi: [10.2307/1990152](https://doi.org/10.2307/1990152).
         2. Doob, J. L. “Markoff Chains--Denumerable Case.” *Transactions of the
            American Mathematical Society* **58**, 455--473 (1945).
            doi: [10.2307/1990339](https://doi.org/10.2307/1990339).
         3. Gillespie, D. T. “A General Method for Numerically Simulating the
            Stochastic Time Evolution of Coupled Chemical Reactions.” *Journal
            of Computational Physics* **22**, 403--434 (1976). doi:
            [10.1016/0021-9991(76)90041-3](
            https://doi.org/10.1016/0021-9991(76)90041-3).
        &#34;&#34;&#34;
        t = self.transition_times[0]
        x = self.micro_states[0]
        while t &lt; self.config.final_time:
            t, x = iterate(do_step, rng, t, x)
        self._micro_states = np.array(self.micro_states)
        self._transition_times = np.array(self.transition_times)
        self._update_states()

    def _check_sizes(self):
        &#34;&#34;&#34;Check the consistency of the network&#39;s size and the initial state.&#34;&#34;&#34;
        if len(self.config.micro_initial_state) != self.config.network.size():
            raise PopNetError(&#39;The size of the network has changed since the &#39;
                              &#39;microscopic initial state was set. Reset the &#39;
                              &#39;simulator before to run it. The network\&#39;s &#39;
                              &#39;parameters might also have to be reset.&#39;)

    def _direct_method(self, rng, t, next_states, rates):
        &#34;&#34;&#34;Obtain the next state and time from the direct method.&#34;&#34;&#34;
        out_rate = np.sum(rates)
        threshold_rate = rng.random() * out_rate
        j = 0
        sum_of_rates = rates[0]
        while sum_of_rates &lt; threshold_rate:
            sum_of_rates += rates[j+1]
            j += 1
        return j, (1 / out_rate) * np.log(1 / rng.random())

    def _first_reaction_method(self, rng, t, next_states, rates):
        &#34;&#34;&#34;Obtain the next state and time from the first reaction method.&#34;&#34;&#34;
        next_times = (1 / rates) * np.log(1 / rng.random(len(rates)))
        j = np.argmin(next_times)
        return j, next_times[j]

    def _get_calcium_output(self, j, growth_rate, decay_rate):
        &#34;&#34;&#34;Get the calcium concentration in neuron *j* with respect to time.&#34;&#34;&#34;
        binary_state = np.real(self.micro_states[:,j])
        all_activation_indices = np.nonzero(binary_state)[0]
        activation_indices = [k for i,k in enumerate(all_activation_indices)
                              if all_activation_indices[i-1] != k-1]
        calcium = np.zeros((len(activation_indices), 
                            len(self.transition_times)))
        for k, activation_index in enumerate(activation_indices):
            t = self.transition_times[activation_index:] 
            t0 = self.transition_times[activation_index]
            calcium[k,activation_index:] = ((1 - np.exp(-growth_rate * (t-t0)))
                                                * np.exp(-decay_rate * (t-t0)))
        calcium = np.sum(calcium, axis=0)
        return calcium

    def _iterate(self, do_step, rng, t, x):
        &#34;&#34;&#34;Perform a single iteration of a simulation.

        Perform a single iteration of a simulation. 

        Parameters
        ----------
        do_step : function
            Dictates how the Monte Carlo step of Gillespie&#39;s algorithm.
        rng : Generator
            Random number generator.
        t : float
            Current time step.
        x : array_like
            Current state of the network.

        Returns
        -------
        float
            Next time step.
        array_like
            Next state of the network.
        &#34;&#34;&#34;
        next_states, rates = self._next_states_and_rates(x)
        j, time_interval = do_step(rng, t, next_states, rates)
        x = next_states[j].copy()
        t += time_interval
        self.transition_times.append(t)
        self.micro_states.append(x.copy())
        return t, x

    def _make_sigmoid_activation_rate(self, j, J):
        &#34;&#34;&#34;Define a sigmoid activation rate for the `j`th neuron.&#34;&#34;&#34;
        def act(x):
            b = np.dot(self.config.network.W[j], np.real(x)) + self.config.Q[J]
            F_value = self.config.network.populations[J].F(b)
            return self.config.network.alpha[j] * F_value
        return act

    def _make_step_activation_rate(self, j, J):
        &#34;&#34;&#34;Define a step activation rate for the `j`th neuron.&#34;&#34;&#34;
        def act(x):
            b = np.dot(self.config.network.W[j], np.real(x)) + self.config.Q[J]
            if b &lt; self.config.network.theta[j]:
                return 0.
            else:
                return self.config.network.alpha[j]
        return act

    def _make_activation_rate(self, j):
        &#34;&#34;&#34;Define the activation rate function for the `j`th neuron.&#34;&#34;&#34;
        J = 0
        sum_sizes = self.config.network.populations[0].size
        while j &gt; sum_sizes:
            sum_sizes += self.config.network.populations[J+1].size
            J += 1
        if self.activation_rates_shape == &#39;step&#39;:
            return self._make_step_activation_rate(j, J)
        elif self.activation_rates_shape == &#39;sigmoid&#39;:
            return self._make_sigmoid_activation_rate(j, J)
        raise ValueError(f&#39;Unexpected value {self.activation_rates_shape} for &#39;
                         &#39;the shape of the activation rate functions.&#39;)

    def _next_states_and_rates(self, x):
        &#34;&#34;&#34;Get all possible states to which the network can go from `x`.

        Knowing that the network is in state `x`, get all states which are 
        accessible next with the rates associated with each possible transition.

        Returns
        -------
        tuple of array_like
            The next possible states, and the associated transition rates. Both
            arrays are arranged so that the *j*th element of the transition rate
            vector is the rate at which the network can make a transition to the
            state corresponding to the *j*th row of the array of next states.
        &#34;&#34;&#34;
        next_states = np.resize(x, (N := self.config.network.size(), N))
        rates = np.zeros(N)
        for j in range(N):
            next_states[j,j], rates[j] = self._next_state_and_rate(j, x)
        return next_states, rates

    def _next_state_and_rate(self, j, x):
        &#34;&#34;&#34;Get the next state and transition rate of the `j`th neuron.

        Knowing that the network is in state `x`, get the next accessible state
        of `j`th neuron, with the rate at which this neuron will make a 
        transition. 

        Parameters
        ----------
        j : int
            The neuron for which to get the next state and transition rate.
        x : array_like
            The current state of the network.

        Returns
        -------
        tuple of complex and float
            The next state of the `j`th neuron with associated transition rate. 

        Raises
        ------
        ValueError
            If the `j`th neuron is in a non valid state. 
        &#34;&#34;&#34;
        if (z := x[j]) == 0.:
            return 1., self.activation_rates[j](x)
        if z == 1.:
            return 1j, self.config.network.beta[j]
        if z == 1j:
            return 0., self.config.network.gamma[j]
        raise ValueError(&#39;The state of a neuron must always be 0, 1 or the &#39;
                         &#39;imaginary unit.&#39;)

    def _reset_activation_rates(self):
        &#34;&#34;&#34;Reset the activation rate functions.&#34;&#34;&#34;
        self._activation_rates = [self._make_activation_rate(j)
                                  for j in range(self.config.network.size())]

    def _state_length(self):
        &#34;&#34;&#34;Length of the macroscopic states.&#34;&#34;&#34;
        return 2 * len(self.config.network.populations)

    def _update_states(self):
        &#34;&#34;&#34;Update `states` based on `micro_states`.

        Compute the macroscopic states of the network from `micro_states`, and
        update `states` in consequence.
        &#34;&#34;&#34;
        p = len(self.config.network.populations)
        states = np.zeros((len(self.transition_times), 2*p))
        j = 0
        for J, popJ in enumerate(self.config.network.populations):
            states[:,J]   = np.sum(np.real(self.micro_states[:,j:j+popJ.size]), 
                                axis=1) / popJ.size
            states[:,p+J] = np.sum(np.imag(self.micro_states[:,j:j+popJ.size]), 
                                axis=1) / popJ.size
            j += popJ.size
        self._states = states


class SimpleSimulator(Simulator):
    &#34;&#34;&#34;Perform single simulations of a stochastic process on a network.

    `SimpleSimulator` extends `Simulator` to ease the task of running single
    simulations of a stochastic process. It has dedicated methods to run
    simulations and output a `popnet.graphics.Trajectory` instance. Its data
    attributes are the same as in the base class.

    The initialization parameters are the same as in the base class.

    &#34;&#34;&#34;

    def run(self, method=&#39;direct&#39;, verbose=False):
        &#34;&#34;&#34;Run a simulation.

        Run a simulation to obtain a possible trajectory of a stochastic
        process that rules the evolution of the network&#39;s state. To obtain this
        trajectory, we use the Doob--Gillespie algorithm, either with the direct
        or with the first reaction method. See `Simulator.single_run` for more
        details about the Doob--Gillespie algorithm.

        Parameters
        ----------
        method : {&#39;direct&#39;, &#39;first reaction&#39;}, optional
            Chooses which method is used to perform the Monte Carlo step in the
            Doob--Gillespie algorithm. Defaults to `&#39;direct&#39;`.
        verbose : bool, optional
            If `True`, the current time is printed at each iteration. Defaults
            to `False`.

        Raises
        ------
        popnet.exceptions.PopNetError
            If the length of the microscopic initial state is different from
            the network&#39;s size.
        ValueError
            If an unexpected value is passed to `method`.
        &#34;&#34;&#34;
        self._check_sizes()
        if method == &#39;direct&#39;:
            def do_step(rng,t,ns,r): return self._direct_method(rng,t,ns,r)
        elif method == &#39;first reaction&#39;:
            def do_step(rng,t,ns,r): return self._first_reaction_method(rng,t,ns,r)
        else:
            raise ValueError(f&#39;Unexpected method {method}. Valid values are &#39;
                             &#39;\&#39;direct\&#39; and \&#39;first reaction\&#39;.&#39;)
        if verbose:
            def iterate(do_step, rng, t, x):
                print(f&#39;t = {t:&lt;.2f}&#39;, end=&#39;\r&#39;)
                return self._iterate(do_step, rng, t, x)
        else:
            def iterate(do_step, rng, t, x): 
                return self._iterate(do_step, rng, t, x)
        self.single_run(np.random.default_rng(), do_step, iterate)
        if verbose:
            print(10*&#39; &#39;, end=&#39;\r&#39;)
            print(&#39;Done!&#39;)
        self._success = True

    def save_output(self, name=None, folder=None):
        &#34;&#34;&#34;Save the simulation&#39;s output to a text file.

        Extends the base class method by saving additionally the times at which
        transitions occur. This is done by saving the array
        `Simulator.transition_times` under *ID - name (times).txt*, where *ID*
        is the ID of the configuration used for the simulation, and *name* is
        `name`.

        Parameters
        ----------
        name : str, optional
            Name to give to the saved output. Defaults to `None`, in which case
            it is replaced with `&#39;Trajectory&#39;`.
        folder : str, optional
            A folder in which the files are saved. If it does not exist in the
            current directory, it is created. Defaults to `None`, in which case
            the files are saved in the current directory.

        Returns
        -------
        name : str
            Name given to the saved output.

        Raises
        ------
        popnet.exceptions.PopNetError
            If the simulation has not been performed yet.
        &#34;&#34;&#34;
        name = super().save_output(name=name, folder=folder)
        filename = _internals._format_filename(folder, self.config.ID,
                                               f&#39;{name} (times)&#39;)
        np.savetxt(filename, self.transition_times, fmt=&#39;%+.12f&#39;)
        return name

    def _output_times(self):
        &#34;&#34;&#34;Times array to output.&#34;&#34;&#34;
        return self.transition_times


class ChainSimulator(Simulator):
    &#34;&#34;&#34;Simulate multiple times a stochastic process on a network.

    `ChainSimulator` extends `Simulator` to ease the task of running many
    simulations of a stochastic process on the same network with the same
    configuration in order to obtain statistics. It has dedicated methods to
    run many simulations and output a `popnet.graphics.Statistics` instance.
    Its data attributes are the same as in the base, except for a new
    `ChainSimulator.samples`, which stores the trajectories obtained from
    simulations of the stochastic process.

    The initialization parameters are the same as in the base class.

    &#34;&#34;&#34;

    @property
    def samples(self):
        &#34;&#34;&#34;Samples of trajectories.

        Samples of trajectories of the stochastic process. It does not contain
        any relevant data at initialization or right after a reset, but it is
        updated during a call to `ChainSimulator.run`. It is a three
        dimensional array, where the first axis is time, the second is the
        macroscopic state component, and the third is associated with a given
        trajectory. It cannot be manually set nor deleted.
        &#34;&#34;&#34;
        return self._samples

    def close(self):
        &#34;&#34;&#34;Delete all data attributes of the simulator.&#34;&#34;&#34;
        super().close()
        del self._samples

    def reset(self):
        &#34;&#34;&#34;Reset the simulator.

        Reset the simulator to run it again. It extends the base class method
        by also resetting `ChainSimulator.samples`.
        &#34;&#34;&#34;
        super().reset()
        self._samples = None

    def run(self, method=&#39;direct&#39;, initial_state=&#39;fixed&#39;, verbose=False):
        &#34;&#34;&#34;Run multiple simulations.

        Run multiple simulations of a stochastic process that describes the
        evolution of the network&#39;s state in order to obtain a sample of
        possible trajectories. The number of simulations performed is given by
        the `popnet.structures.MicroConfiguration.executions` attribute of the
        configuration. Each individual simulation is performed with the
        Doob--Gillespie algorithm, either with the direct or the first reaction
        method. See `Simulator.single_run` for more details about the
        Doob--Gillespie algorithm.

        Parameters
        ----------
        method : {&#39;direct&#39;, &#39;first reaction&#39;}, optional
            Chooses which method is used to perform the Monte Carlo step in the
            Doob--Gillespie algorithm. Defaults to `&#39;direct&#39;`.
        initial_state : {&#39;fixed&#39;, &#39;random&#39;}, optional
            If `&#39;fixed&#39;`, the microscopic initial state is the same in all
            simulations. If `&#39;random&#39;`, the microscopic initial state is reset
            randomly with
            `popnet.structures.MicroConfiguration.reset_micro_initial_state`
            between each simulation. Defaults to `&#39;fixed&#39;`.
        verbose : bool, optional
            If `True`, a progression bar is printed to show how much of the
            simulations have been performed. Defaults to `False`.

        Raises
        ------
        popnet.exceptions.PopNetError
            If the length of the microscopic initial state is different from
            the network&#39;s size.
        ValueError
            If an unexpected value is passed to `method` or to `initial_state`.
        &#34;&#34;&#34;
        self._check_sizes()
        samples = np.zeros((1+self.config.iterations, self._state_length(), 
                            self.config.executions))
        if method == &#39;direct&#39;:
            def do_step(rng,t,ns,r): return self._direct_method(rng,t,ns,r)
        elif method == &#39;first reaction&#39;:
            def do_step(rng,t,ns,r): return self._first_reaction_method(rng,t,ns,r)
        else:
            raise ValueError(f&#39;Unexpected method {method}. Valid values are &#39;
                             &#39;\&#39;direct\&#39; and \&#39;first reaction\&#39;.&#39;)
        if initial_state == &#39;fixed&#39;:
            def reset_initial_state(): pass
        elif initial_state == &#39;random&#39;:
            def reset_initial_state(): self.config.reset_micro_initial_state()
        else:
            raise ValueError(f&#39;Unexpected keyword {initial_state} to choose the&#39;
                             &#39; initial state. Valid values are \&#39;fixed\&#39; and &#39;
                             &#39;\&#39;random\&#39;.&#39;)
        if verbose:
            def progress(rg): return tqdm(rg)
        else:
            def progress(rg): return rg
        rng = np.random.default_rng()
        for j in progress(range(self.config.executions)):
            self.single_run(rng, do_step, self._iterate)
            for J in range(self._state_length()):
                samples[:,J,j] = np.interp(self.times, self.transition_times, 
                                           self.states.T[J])
            reset_initial_state()
            self.reset()
        self._samples = samples
        self._success = True

    def save_output(self, name=None, folder=None):
        &#34;&#34;&#34;Save the samples obtained from simulations.

        Overrides the base class method to save the samples of trajectories
        obtained from numerical simulations rather than the macroscopic states
        they yield. Each state component *X* is saved in its own file, named
        *ID - name X.txt*, where *ID* is the ID of the configuration used for
        the simulations, and *name* is `name`.

        Parameters
        ----------
        name : str, optional
            Name to give to the saved samples. Defaults to `None`, in which case
            it is replaced with `&#39;Sample&#39;`.
        folder : str, optional
            A folder in which the files are saved. If it does not exist in the
            current directory, it is created. Defaults to `None`, in which case
            the files are saved in the current directory.

        Returns
        -------
        name : str
            Name given to the saved samples.

        Raises
        ------
        popnet.exceptions.PopNetError
            If the simulations have not been performed yet.
        &#34;&#34;&#34;
        self._check_if_run()
        name = self._output_type._get_sample_name(name)
        _internals._make_sure_folder_exists(folder)
        for J, X in enumerate(self.config._variables[:self._state_length()]):
            filename = _internals._format_filename(folder, self.config.ID,
                                                   f&#39;{name} {X}&#39;)
            h = (f&#39;In each column are the values of {X} with respect to time &#39;
                 &#39;for a given trajectory.&#39;)
            np.savetxt(filename, self.samples[:,J,:], fmt=&#39;%+.12f&#39;, header=h)
        return name

    def _output_states(self):
        &#34;&#34;&#34;States array to output.&#34;&#34;&#34;
        return self.samples


OUTPUT_TYPES = {systems.WilsonCowanSystem: graphics.Solution,
                systems.MeanFieldSystem: graphics.Solution,
                systems.MixedSystem: graphics.Solution,
                systems.TaylorExtendedSystem: graphics.ExtendedSolution,
                systems._TaylorExtendedSystemOne: graphics.ExtendedSolution,
                systems.ExtendedSystem: graphics.ExtendedSolution,
                SimpleSimulator: graphics.Trajectory,
                ChainSimulator: graphics.Statistics}
&#34;&#34;&#34;Type in which an execution is to be output, indexed by
`popnet.systems.DynamicalSystem` or by `Simulator` subclass.&#34;&#34;&#34;


@singledispatch
def get_integrator(arg, system_name=None, lyapunov=False, **kwargs):
    &#34;&#34;&#34;Get a numerical integrator.

    Define a numerical integrator, either from a dynamical system or from a
    configuration and a keyword specifying which dynamical system is to be
    integrated.

    Parameters
    ----------
    arg : popnet.systems.DynamicalSystem or popnet.structures.Configuration
        Either a dynamical system to integrate, or a configuration to associate
        with the integrator.
    system_name : str, optional
        Decides which dynamical system is integrated when `arg` is a
        configuration. It is in fact mandatory when `arg` is a configuration,
        but has no effect when it is a dynamical system. The following values
        are accepted.

         - `&#39;mean-field&#39;`: the Wilson--Cowan&#39;s model with refractory state.
         - `&#39;wilson-cowan&#39;`: an equivalent to the original Wilson--Cowan model.
         - `&#39;mixed&#39;`: the mean field one, but with an additional parameter
           multiplying the refractory states&#39; derivates.
         - `&#39;taylor&#39;`: the extended Wilson--Cowan model with the closure
           resulting from a second-order Taylor approximation.
         - `&#39;extended&#39;`: the extended Wilson--Cowan model with the closure
           based on sigmoid functions.
    lyapunov : bool, optional
        Decides if the integrator is defined to compute Lyapunov exponents
        while integrating the system. For this to work, the dynamical system
        must implement a Jacobian matrix.

    **kwargs
        Keywords arguments passed to the class constructor.

    Returns
    -------
    Integrator or LyapunovExponentsIntegrator
        Integrator initialized with given parameters.

    Raises
    ------
    popnet.exceptions.PopNetError
        If `system_name` is given a non-valid value or if the requested
        dynamical system does not implement a Jacobian matrix.
    TypeError
        If `arg` is neither a `popnet.structures.Configuration` instance nor a
        `popnet.systems.DynamicalSystem` instance.
    &#34;&#34;&#34;
    raise TypeError(&#39;\&#39;get_integrator\&#39; expects its first argument to be either&#39;
                    &#39; a \&#39;Configuration\&#39; or a \&#39;DynamicalSystem\&#39; instance.&#39;) 


@get_integrator.register(structures.Configuration)
def _(config, system_name=None, lyapunov=False, **kwargs):
    system = systems.get_system(config, system_name=system_name)
    if lyapunov:
        return LyapunovExponentsIntegrator(system, **kwargs)
    return Integrator(system, **kwargs)


@get_integrator.register(systems.DynamicalSystem)
def _(system, system_name=None, lyapunov=False, **kwargs):
    if lyapunov:
        return LyapunovExponentsIntegrator(system, **kwargs)
    return Integrator(system, **kwargs)



def get_simulator(config, act=&#39;step&#39;, mode=&#39;individual&#39;):
    &#34;&#34;&#34;Get a simulator to perform stochastic simulations.

    Define a simulator in order to perform either individual simulations, or
    chains of simulations.

    Parameters
    ----------
    config : popnet.structures.Configuration
        Configuration to associate with the simulator.
    act : {&#39;step&#39;, &#39;sigmoid&#39;}, optional
        Shape of neurons&#39; activation rates. If `&#39;step&#39;`, a neuron&#39;s activation
        rate is a step function going from zero to
        `popnet.structures.MicroNetwork.alpha` at its threshold
        `popnet.structures.MicroNetwork.theta`. If `&#39;sigmoid&#39;`, a neuron&#39;s
        activation rate is the logistic function
        `popnet.structures.Population.F` of the population to which it belongs.
        Defaults to `&#39;step&#39;`.
    mode : {&#39;individual&#39;, &#39;chain&#39;}, optional
        How the simulations are to be executed. If `&#39;individual&#39;`, the simulator
        is defined to run one simulation at a time. If `&#39;chain&#39;`, it is rather
        defined to run a sequence of simulations at every run. Defaults to
        `&#39;individual&#39;`.

    Returns
    -------
    SimpleSimulator or ChainSimulator
        Simulator initialized with given configuration.

    Raises
    ------
    popnet.exceptions.PopNetError
        If `mode` is given an unexpected value.
    &#34;&#34;&#34;
    if mode == &#39;individual&#39;:
        return SimpleSimulator(config, act=act)
    elif mode == &#39;chain&#39;:
        return ChainSimulator(config, act=act)
    raise PopNetError(f&#39;Unknown execution mode {mode}. Valid values are &#39;
                      &#39;\&#39;individual\&#39; and \&#39;chain\&#39;.&#39;)</code></pre>
</details>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-variables">Global variables</h2>
<dl>
<dt id="popnet.executors.OUTPUT_TYPES"><code class="name">var <span class="ident">OUTPUT_TYPES</span></code></dt>
<dd>
<div class="desc"><p>Type in which an execution is to be output, indexed by
<code><a title="popnet.systems.DynamicalSystem" href="systems.html#popnet.systems.DynamicalSystem">DynamicalSystem</a></code> or by <code><a title="popnet.executors.Simulator" href="#popnet.executors.Simulator">Simulator</a></code> subclass.</p></div>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="popnet.executors.get_integrator"><code class="name flex">
<span>def <span class="ident">get_integrator</span></span>(<span>arg, system_name=None, lyapunov=False, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Get a numerical integrator.</p>
<p>Define a numerical integrator, either from a dynamical system or from a
configuration and a keyword specifying which dynamical system is to be
integrated.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>arg</code></strong> :&ensp;<code><a title="popnet.systems.DynamicalSystem" href="systems.html#popnet.systems.DynamicalSystem">DynamicalSystem</a></code> or <code><a title="popnet.structures.Configuration" href="structures.html#popnet.structures.Configuration">Configuration</a></code></dt>
<dd>Either a dynamical system to integrate, or a configuration to associate
with the integrator.</dd>
<dt><strong><code>system_name</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>
<p>Decides which dynamical system is integrated when <code>arg</code> is a
configuration. It is in fact mandatory when <code>arg</code> is a configuration,
but has no effect when it is a dynamical system. The following values
are accepted.</p>
<ul>
<li><code>'mean-field'</code>: the Wilson&ndash;Cowan's model with refractory state.</li>
<li><code>'wilson-cowan'</code>: an equivalent to the original Wilson&ndash;Cowan model.</li>
<li><code>'mixed'</code>: the mean field one, but with an additional parameter
multiplying the refractory states' derivates.</li>
<li><code>'taylor'</code>: the extended Wilson&ndash;Cowan model with the closure
resulting from a second-order Taylor approximation.</li>
<li><code>'extended'</code>: the extended Wilson&ndash;Cowan model with the closure
based on sigmoid functions.</li>
</ul>
</dd>
<dt><strong><code>lyapunov</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Decides if the integrator is defined to compute Lyapunov exponents
while integrating the system. For this to work, the dynamical system
must implement a Jacobian matrix.</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Keywords arguments passed to the class constructor.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="popnet.executors.Integrator" href="#popnet.executors.Integrator">Integrator</a></code> or <code><a title="popnet.executors.LyapunovExponentsIntegrator" href="#popnet.executors.LyapunovExponentsIntegrator">LyapunovExponentsIntegrator</a></code></dt>
<dd>Integrator initialized with given parameters.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code><a title="popnet.exceptions.PopNetError" href="exceptions.html#popnet.exceptions.PopNetError">PopNetError</a></code></dt>
<dd>If <code>system_name</code> is given a non-valid value or if the requested
dynamical system does not implement a Jacobian matrix.</dd>
<dt><code>TypeError</code></dt>
<dd>If <code>arg</code> is neither a <code><a title="popnet.structures.Configuration" href="structures.html#popnet.structures.Configuration">Configuration</a></code> instance nor a
<code><a title="popnet.systems.DynamicalSystem" href="systems.html#popnet.systems.DynamicalSystem">DynamicalSystem</a></code> instance.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@singledispatch
def get_integrator(arg, system_name=None, lyapunov=False, **kwargs):
    &#34;&#34;&#34;Get a numerical integrator.

    Define a numerical integrator, either from a dynamical system or from a
    configuration and a keyword specifying which dynamical system is to be
    integrated.

    Parameters
    ----------
    arg : popnet.systems.DynamicalSystem or popnet.structures.Configuration
        Either a dynamical system to integrate, or a configuration to associate
        with the integrator.
    system_name : str, optional
        Decides which dynamical system is integrated when `arg` is a
        configuration. It is in fact mandatory when `arg` is a configuration,
        but has no effect when it is a dynamical system. The following values
        are accepted.

         - `&#39;mean-field&#39;`: the Wilson--Cowan&#39;s model with refractory state.
         - `&#39;wilson-cowan&#39;`: an equivalent to the original Wilson--Cowan model.
         - `&#39;mixed&#39;`: the mean field one, but with an additional parameter
           multiplying the refractory states&#39; derivates.
         - `&#39;taylor&#39;`: the extended Wilson--Cowan model with the closure
           resulting from a second-order Taylor approximation.
         - `&#39;extended&#39;`: the extended Wilson--Cowan model with the closure
           based on sigmoid functions.
    lyapunov : bool, optional
        Decides if the integrator is defined to compute Lyapunov exponents
        while integrating the system. For this to work, the dynamical system
        must implement a Jacobian matrix.

    **kwargs
        Keywords arguments passed to the class constructor.

    Returns
    -------
    Integrator or LyapunovExponentsIntegrator
        Integrator initialized with given parameters.

    Raises
    ------
    popnet.exceptions.PopNetError
        If `system_name` is given a non-valid value or if the requested
        dynamical system does not implement a Jacobian matrix.
    TypeError
        If `arg` is neither a `popnet.structures.Configuration` instance nor a
        `popnet.systems.DynamicalSystem` instance.
    &#34;&#34;&#34;
    raise TypeError(&#39;\&#39;get_integrator\&#39; expects its first argument to be either&#39;
                    &#39; a \&#39;Configuration\&#39; or a \&#39;DynamicalSystem\&#39; instance.&#39;) </code></pre>
</details>
</dd>
<dt id="popnet.executors.get_simulator"><code class="name flex">
<span>def <span class="ident">get_simulator</span></span>(<span>config, act='step', mode='individual')</span>
</code></dt>
<dd>
<div class="desc"><p>Get a simulator to perform stochastic simulations.</p>
<p>Define a simulator in order to perform either individual simulations, or
chains of simulations.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>config</code></strong> :&ensp;<code><a title="popnet.structures.Configuration" href="structures.html#popnet.structures.Configuration">Configuration</a></code></dt>
<dd>Configuration to associate with the simulator.</dd>
<dt><strong><code>act</code></strong> :&ensp;<code>{'step', 'sigmoid'}</code>, optional</dt>
<dd>Shape of neurons' activation rates. If <code>'step'</code>, a neuron's activation
rate is a step function going from zero to
<code><a title="popnet.structures.MicroNetwork.alpha" href="structures.html#popnet.structures.MicroNetwork.alpha">MicroNetwork.alpha</a></code> at its threshold
<code><a title="popnet.structures.MicroNetwork.theta" href="structures.html#popnet.structures.MicroNetwork.theta">MicroNetwork.theta</a></code>. If <code>'sigmoid'</code>, a neuron's
activation rate is the logistic function
<code><a title="popnet.structures.Population.F" href="structures.html#popnet.structures.Population.F">Population.F()</a></code> of the population to which it belongs.
Defaults to <code>'step'</code>.</dd>
<dt><strong><code>mode</code></strong> :&ensp;<code>{'individual', 'chain'}</code>, optional</dt>
<dd>How the simulations are to be executed. If <code>'individual'</code>, the simulator
is defined to run one simulation at a time. If <code>'chain'</code>, it is rather
defined to run a sequence of simulations at every run. Defaults to
<code>'individual'</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="popnet.executors.SimpleSimulator" href="#popnet.executors.SimpleSimulator">SimpleSimulator</a></code> or <code><a title="popnet.executors.ChainSimulator" href="#popnet.executors.ChainSimulator">ChainSimulator</a></code></dt>
<dd>Simulator initialized with given configuration.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code><a title="popnet.exceptions.PopNetError" href="exceptions.html#popnet.exceptions.PopNetError">PopNetError</a></code></dt>
<dd>If <code>mode</code> is given an unexpected value.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_simulator(config, act=&#39;step&#39;, mode=&#39;individual&#39;):
    &#34;&#34;&#34;Get a simulator to perform stochastic simulations.

    Define a simulator in order to perform either individual simulations, or
    chains of simulations.

    Parameters
    ----------
    config : popnet.structures.Configuration
        Configuration to associate with the simulator.
    act : {&#39;step&#39;, &#39;sigmoid&#39;}, optional
        Shape of neurons&#39; activation rates. If `&#39;step&#39;`, a neuron&#39;s activation
        rate is a step function going from zero to
        `popnet.structures.MicroNetwork.alpha` at its threshold
        `popnet.structures.MicroNetwork.theta`. If `&#39;sigmoid&#39;`, a neuron&#39;s
        activation rate is the logistic function
        `popnet.structures.Population.F` of the population to which it belongs.
        Defaults to `&#39;step&#39;`.
    mode : {&#39;individual&#39;, &#39;chain&#39;}, optional
        How the simulations are to be executed. If `&#39;individual&#39;`, the simulator
        is defined to run one simulation at a time. If `&#39;chain&#39;`, it is rather
        defined to run a sequence of simulations at every run. Defaults to
        `&#39;individual&#39;`.

    Returns
    -------
    SimpleSimulator or ChainSimulator
        Simulator initialized with given configuration.

    Raises
    ------
    popnet.exceptions.PopNetError
        If `mode` is given an unexpected value.
    &#34;&#34;&#34;
    if mode == &#39;individual&#39;:
        return SimpleSimulator(config, act=act)
    elif mode == &#39;chain&#39;:
        return ChainSimulator(config, act=act)
    raise PopNetError(f&#39;Unknown execution mode {mode}. Valid values are &#39;
                      &#39;\&#39;individual\&#39; and \&#39;chain\&#39;.&#39;)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="popnet.executors.ChainSimulator"><code class="flex name class">
<span>class <span class="ident">ChainSimulator</span></span>
<span>(</span><span>config, act='step', **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Simulate multiple times a stochastic process on a network.</p>
<p><code><a title="popnet.executors.ChainSimulator" href="#popnet.executors.ChainSimulator">ChainSimulator</a></code> extends <code><a title="popnet.executors.Simulator" href="#popnet.executors.Simulator">Simulator</a></code> to ease the task of running many
simulations of a stochastic process on the same network with the same
configuration in order to obtain statistics. It has dedicated methods to
run many simulations and output a <code><a title="popnet.graphics.Statistics" href="graphics.html#popnet.graphics.Statistics">Statistics</a></code> instance.
Its data attributes are the same as in the base, except for a new
<code><a title="popnet.executors.ChainSimulator.samples" href="#popnet.executors.ChainSimulator.samples">ChainSimulator.samples</a></code>, which stores the trajectories obtained from
simulations of the stochastic process.</p>
<p>The initialization parameters are the same as in the base class.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ChainSimulator(Simulator):
    &#34;&#34;&#34;Simulate multiple times a stochastic process on a network.

    `ChainSimulator` extends `Simulator` to ease the task of running many
    simulations of a stochastic process on the same network with the same
    configuration in order to obtain statistics. It has dedicated methods to
    run many simulations and output a `popnet.graphics.Statistics` instance.
    Its data attributes are the same as in the base, except for a new
    `ChainSimulator.samples`, which stores the trajectories obtained from
    simulations of the stochastic process.

    The initialization parameters are the same as in the base class.

    &#34;&#34;&#34;

    @property
    def samples(self):
        &#34;&#34;&#34;Samples of trajectories.

        Samples of trajectories of the stochastic process. It does not contain
        any relevant data at initialization or right after a reset, but it is
        updated during a call to `ChainSimulator.run`. It is a three
        dimensional array, where the first axis is time, the second is the
        macroscopic state component, and the third is associated with a given
        trajectory. It cannot be manually set nor deleted.
        &#34;&#34;&#34;
        return self._samples

    def close(self):
        &#34;&#34;&#34;Delete all data attributes of the simulator.&#34;&#34;&#34;
        super().close()
        del self._samples

    def reset(self):
        &#34;&#34;&#34;Reset the simulator.

        Reset the simulator to run it again. It extends the base class method
        by also resetting `ChainSimulator.samples`.
        &#34;&#34;&#34;
        super().reset()
        self._samples = None

    def run(self, method=&#39;direct&#39;, initial_state=&#39;fixed&#39;, verbose=False):
        &#34;&#34;&#34;Run multiple simulations.

        Run multiple simulations of a stochastic process that describes the
        evolution of the network&#39;s state in order to obtain a sample of
        possible trajectories. The number of simulations performed is given by
        the `popnet.structures.MicroConfiguration.executions` attribute of the
        configuration. Each individual simulation is performed with the
        Doob--Gillespie algorithm, either with the direct or the first reaction
        method. See `Simulator.single_run` for more details about the
        Doob--Gillespie algorithm.

        Parameters
        ----------
        method : {&#39;direct&#39;, &#39;first reaction&#39;}, optional
            Chooses which method is used to perform the Monte Carlo step in the
            Doob--Gillespie algorithm. Defaults to `&#39;direct&#39;`.
        initial_state : {&#39;fixed&#39;, &#39;random&#39;}, optional
            If `&#39;fixed&#39;`, the microscopic initial state is the same in all
            simulations. If `&#39;random&#39;`, the microscopic initial state is reset
            randomly with
            `popnet.structures.MicroConfiguration.reset_micro_initial_state`
            between each simulation. Defaults to `&#39;fixed&#39;`.
        verbose : bool, optional
            If `True`, a progression bar is printed to show how much of the
            simulations have been performed. Defaults to `False`.

        Raises
        ------
        popnet.exceptions.PopNetError
            If the length of the microscopic initial state is different from
            the network&#39;s size.
        ValueError
            If an unexpected value is passed to `method` or to `initial_state`.
        &#34;&#34;&#34;
        self._check_sizes()
        samples = np.zeros((1+self.config.iterations, self._state_length(), 
                            self.config.executions))
        if method == &#39;direct&#39;:
            def do_step(rng,t,ns,r): return self._direct_method(rng,t,ns,r)
        elif method == &#39;first reaction&#39;:
            def do_step(rng,t,ns,r): return self._first_reaction_method(rng,t,ns,r)
        else:
            raise ValueError(f&#39;Unexpected method {method}. Valid values are &#39;
                             &#39;\&#39;direct\&#39; and \&#39;first reaction\&#39;.&#39;)
        if initial_state == &#39;fixed&#39;:
            def reset_initial_state(): pass
        elif initial_state == &#39;random&#39;:
            def reset_initial_state(): self.config.reset_micro_initial_state()
        else:
            raise ValueError(f&#39;Unexpected keyword {initial_state} to choose the&#39;
                             &#39; initial state. Valid values are \&#39;fixed\&#39; and &#39;
                             &#39;\&#39;random\&#39;.&#39;)
        if verbose:
            def progress(rg): return tqdm(rg)
        else:
            def progress(rg): return rg
        rng = np.random.default_rng()
        for j in progress(range(self.config.executions)):
            self.single_run(rng, do_step, self._iterate)
            for J in range(self._state_length()):
                samples[:,J,j] = np.interp(self.times, self.transition_times, 
                                           self.states.T[J])
            reset_initial_state()
            self.reset()
        self._samples = samples
        self._success = True

    def save_output(self, name=None, folder=None):
        &#34;&#34;&#34;Save the samples obtained from simulations.

        Overrides the base class method to save the samples of trajectories
        obtained from numerical simulations rather than the macroscopic states
        they yield. Each state component *X* is saved in its own file, named
        *ID - name X.txt*, where *ID* is the ID of the configuration used for
        the simulations, and *name* is `name`.

        Parameters
        ----------
        name : str, optional
            Name to give to the saved samples. Defaults to `None`, in which case
            it is replaced with `&#39;Sample&#39;`.
        folder : str, optional
            A folder in which the files are saved. If it does not exist in the
            current directory, it is created. Defaults to `None`, in which case
            the files are saved in the current directory.

        Returns
        -------
        name : str
            Name given to the saved samples.

        Raises
        ------
        popnet.exceptions.PopNetError
            If the simulations have not been performed yet.
        &#34;&#34;&#34;
        self._check_if_run()
        name = self._output_type._get_sample_name(name)
        _internals._make_sure_folder_exists(folder)
        for J, X in enumerate(self.config._variables[:self._state_length()]):
            filename = _internals._format_filename(folder, self.config.ID,
                                                   f&#39;{name} {X}&#39;)
            h = (f&#39;In each column are the values of {X} with respect to time &#39;
                 &#39;for a given trajectory.&#39;)
            np.savetxt(filename, self.samples[:,J,:], fmt=&#39;%+.12f&#39;, header=h)
        return name

    def _output_states(self):
        &#34;&#34;&#34;States array to output.&#34;&#34;&#34;
        return self.samples</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="popnet.executors.Simulator" href="#popnet.executors.Simulator">Simulator</a></li>
<li><a title="popnet.executors.Executor" href="#popnet.executors.Executor">Executor</a></li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="popnet.executors.ChainSimulator.samples"><code class="name">var <span class="ident">samples</span></code></dt>
<dd>
<div class="desc"><p>Samples of trajectories.</p>
<p>Samples of trajectories of the stochastic process. It does not contain
any relevant data at initialization or right after a reset, but it is
updated during a call to <code><a title="popnet.executors.ChainSimulator.run" href="#popnet.executors.ChainSimulator.run">ChainSimulator.run()</a></code>. It is a three
dimensional array, where the first axis is time, the second is the
macroscopic state component, and the third is associated with a given
trajectory. It cannot be manually set nor deleted.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def samples(self):
    &#34;&#34;&#34;Samples of trajectories.

    Samples of trajectories of the stochastic process. It does not contain
    any relevant data at initialization or right after a reset, but it is
    updated during a call to `ChainSimulator.run`. It is a three
    dimensional array, where the first axis is time, the second is the
    macroscopic state component, and the third is associated with a given
    trajectory. It cannot be manually set nor deleted.
    &#34;&#34;&#34;
    return self._samples</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="popnet.executors.ChainSimulator.reset"><code class="name flex">
<span>def <span class="ident">reset</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Reset the simulator.</p>
<p>Reset the simulator to run it again. It extends the base class method
by also resetting <code><a title="popnet.executors.ChainSimulator.samples" href="#popnet.executors.ChainSimulator.samples">ChainSimulator.samples</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset(self):
    &#34;&#34;&#34;Reset the simulator.

    Reset the simulator to run it again. It extends the base class method
    by also resetting `ChainSimulator.samples`.
    &#34;&#34;&#34;
    super().reset()
    self._samples = None</code></pre>
</details>
</dd>
<dt id="popnet.executors.ChainSimulator.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>self, method='direct', initial_state='fixed', verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Run multiple simulations.</p>
<p>Run multiple simulations of a stochastic process that describes the
evolution of the network's state in order to obtain a sample of
possible trajectories. The number of simulations performed is given by
the <code><a title="popnet.structures.MicroConfiguration.executions" href="structures.html#popnet.structures.MicroConfiguration.executions">MicroConfiguration.executions</a></code> attribute of the
configuration. Each individual simulation is performed with the
Doob&ndash;Gillespie algorithm, either with the direct or the first reaction
method. See <code><a title="popnet.executors.Simulator.single_run" href="#popnet.executors.Simulator.single_run">Simulator.single_run()</a></code> for more details about the
Doob&ndash;Gillespie algorithm.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>method</code></strong> :&ensp;<code>{'direct', 'first reaction'}</code>, optional</dt>
<dd>Chooses which method is used to perform the Monte Carlo step in the
Doob&ndash;Gillespie algorithm. Defaults to <code>'direct'</code>.</dd>
<dt><strong><code>initial_state</code></strong> :&ensp;<code>{'fixed', 'random'}</code>, optional</dt>
<dd>If <code>'fixed'</code>, the microscopic initial state is the same in all
simulations. If <code>'random'</code>, the microscopic initial state is reset
randomly with
<code><a title="popnet.structures.MicroConfiguration.reset_micro_initial_state" href="structures.html#popnet.structures.MicroConfiguration.reset_micro_initial_state">MicroConfiguration.reset_micro_initial_state()</a></code>
between each simulation. Defaults to <code>'fixed'</code>.</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If <code>True</code>, a progression bar is printed to show how much of the
simulations have been performed. Defaults to <code>False</code>.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code><a title="popnet.exceptions.PopNetError" href="exceptions.html#popnet.exceptions.PopNetError">PopNetError</a></code></dt>
<dd>If the length of the microscopic initial state is different from
the network's size.</dd>
<dt><code>ValueError</code></dt>
<dd>If an unexpected value is passed to <code>method</code> or to <code>initial_state</code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run(self, method=&#39;direct&#39;, initial_state=&#39;fixed&#39;, verbose=False):
    &#34;&#34;&#34;Run multiple simulations.

    Run multiple simulations of a stochastic process that describes the
    evolution of the network&#39;s state in order to obtain a sample of
    possible trajectories. The number of simulations performed is given by
    the `popnet.structures.MicroConfiguration.executions` attribute of the
    configuration. Each individual simulation is performed with the
    Doob--Gillespie algorithm, either with the direct or the first reaction
    method. See `Simulator.single_run` for more details about the
    Doob--Gillespie algorithm.

    Parameters
    ----------
    method : {&#39;direct&#39;, &#39;first reaction&#39;}, optional
        Chooses which method is used to perform the Monte Carlo step in the
        Doob--Gillespie algorithm. Defaults to `&#39;direct&#39;`.
    initial_state : {&#39;fixed&#39;, &#39;random&#39;}, optional
        If `&#39;fixed&#39;`, the microscopic initial state is the same in all
        simulations. If `&#39;random&#39;`, the microscopic initial state is reset
        randomly with
        `popnet.structures.MicroConfiguration.reset_micro_initial_state`
        between each simulation. Defaults to `&#39;fixed&#39;`.
    verbose : bool, optional
        If `True`, a progression bar is printed to show how much of the
        simulations have been performed. Defaults to `False`.

    Raises
    ------
    popnet.exceptions.PopNetError
        If the length of the microscopic initial state is different from
        the network&#39;s size.
    ValueError
        If an unexpected value is passed to `method` or to `initial_state`.
    &#34;&#34;&#34;
    self._check_sizes()
    samples = np.zeros((1+self.config.iterations, self._state_length(), 
                        self.config.executions))
    if method == &#39;direct&#39;:
        def do_step(rng,t,ns,r): return self._direct_method(rng,t,ns,r)
    elif method == &#39;first reaction&#39;:
        def do_step(rng,t,ns,r): return self._first_reaction_method(rng,t,ns,r)
    else:
        raise ValueError(f&#39;Unexpected method {method}. Valid values are &#39;
                         &#39;\&#39;direct\&#39; and \&#39;first reaction\&#39;.&#39;)
    if initial_state == &#39;fixed&#39;:
        def reset_initial_state(): pass
    elif initial_state == &#39;random&#39;:
        def reset_initial_state(): self.config.reset_micro_initial_state()
    else:
        raise ValueError(f&#39;Unexpected keyword {initial_state} to choose the&#39;
                         &#39; initial state. Valid values are \&#39;fixed\&#39; and &#39;
                         &#39;\&#39;random\&#39;.&#39;)
    if verbose:
        def progress(rg): return tqdm(rg)
    else:
        def progress(rg): return rg
    rng = np.random.default_rng()
    for j in progress(range(self.config.executions)):
        self.single_run(rng, do_step, self._iterate)
        for J in range(self._state_length()):
            samples[:,J,j] = np.interp(self.times, self.transition_times, 
                                       self.states.T[J])
        reset_initial_state()
        self.reset()
    self._samples = samples
    self._success = True</code></pre>
</details>
</dd>
<dt id="popnet.executors.ChainSimulator.save_output"><code class="name flex">
<span>def <span class="ident">save_output</span></span>(<span>self, name=None, folder=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Save the samples obtained from simulations.</p>
<p>Overrides the base class method to save the samples of trajectories
obtained from numerical simulations rather than the macroscopic states
they yield. Each state component <em>X</em> is saved in its own file, named
<em>ID - name X.txt</em>, where <em>ID</em> is the ID of the configuration used for
the simulations, and <em>name</em> is <code>name</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Name to give to the saved samples. Defaults to <code>None</code>, in which case
it is replaced with <code>'Sample'</code>.</dd>
<dt><strong><code>folder</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>A folder in which the files are saved. If it does not exist in the
current directory, it is created. Defaults to <code>None</code>, in which case
the files are saved in the current directory.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name given to the saved samples.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code><a title="popnet.exceptions.PopNetError" href="exceptions.html#popnet.exceptions.PopNetError">PopNetError</a></code></dt>
<dd>If the simulations have not been performed yet.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_output(self, name=None, folder=None):
    &#34;&#34;&#34;Save the samples obtained from simulations.

    Overrides the base class method to save the samples of trajectories
    obtained from numerical simulations rather than the macroscopic states
    they yield. Each state component *X* is saved in its own file, named
    *ID - name X.txt*, where *ID* is the ID of the configuration used for
    the simulations, and *name* is `name`.

    Parameters
    ----------
    name : str, optional
        Name to give to the saved samples. Defaults to `None`, in which case
        it is replaced with `&#39;Sample&#39;`.
    folder : str, optional
        A folder in which the files are saved. If it does not exist in the
        current directory, it is created. Defaults to `None`, in which case
        the files are saved in the current directory.

    Returns
    -------
    name : str
        Name given to the saved samples.

    Raises
    ------
    popnet.exceptions.PopNetError
        If the simulations have not been performed yet.
    &#34;&#34;&#34;
    self._check_if_run()
    name = self._output_type._get_sample_name(name)
    _internals._make_sure_folder_exists(folder)
    for J, X in enumerate(self.config._variables[:self._state_length()]):
        filename = _internals._format_filename(folder, self.config.ID,
                                               f&#39;{name} {X}&#39;)
        h = (f&#39;In each column are the values of {X} with respect to time &#39;
             &#39;for a given trajectory.&#39;)
        np.savetxt(filename, self.samples[:,J,:], fmt=&#39;%+.12f&#39;, header=h)
    return name</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="popnet.executors.Simulator" href="#popnet.executors.Simulator">Simulator</a></b></code>:
<ul class="hlist">
<li><code><a title="popnet.executors.Simulator.activation_rates" href="#popnet.executors.Simulator.activation_rates">activation_rates</a></code></li>
<li><code><a title="popnet.executors.Simulator.activation_rates_shape" href="#popnet.executors.Simulator.activation_rates_shape">activation_rates_shape</a></code></li>
<li><code><a title="popnet.executors.Simulator.calcium_output" href="#popnet.executors.Simulator.calcium_output">calcium_output</a></code></li>
<li><code><a title="popnet.executors.Simulator.close" href="#popnet.executors.Simulator.close">close</a></code></li>
<li><code><a title="popnet.executors.Simulator.config" href="#popnet.executors.Executor.config">config</a></code></li>
<li><code><a title="popnet.executors.Simulator.micro_output" href="#popnet.executors.Simulator.micro_output">micro_output</a></code></li>
<li><code><a title="popnet.executors.Simulator.micro_states" href="#popnet.executors.Simulator.micro_states">micro_states</a></code></li>
<li><code><a title="popnet.executors.Simulator.output" href="#popnet.executors.Executor.output">output</a></code></li>
<li><code><a title="popnet.executors.Simulator.single_run" href="#popnet.executors.Simulator.single_run">single_run</a></code></li>
<li><code><a title="popnet.executors.Simulator.states" href="#popnet.executors.Executor.states">states</a></code></li>
<li><code><a title="popnet.executors.Simulator.success" href="#popnet.executors.Executor.success">success</a></code></li>
<li><code><a title="popnet.executors.Simulator.times" href="#popnet.executors.Executor.times">times</a></code></li>
<li><code><a title="popnet.executors.Simulator.transition_times" href="#popnet.executors.Simulator.transition_times">transition_times</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="popnet.executors.Executor"><code class="flex name class">
<span>class <span class="ident">Executor</span></span>
<span>(</span><span>config)</span>
</code></dt>
<dd>
<div class="desc"><p>Execute numerical experiments on a network.</p>
<p><code><a title="popnet.executors.Executor" href="#popnet.executors.Executor">Executor</a></code> is meant to perform numerical experiments to study the dynamics
on a network split into populations. These experiments are intended to be
carried out by subclasses of <code><a title="popnet.executors.Executor" href="#popnet.executors.Executor">Executor</a></code>.</p>
<ul>
<li>To perform simulations of a stochastic process that rules the
evolution of the network, use <code><a title="popnet.executors.Simulator" href="#popnet.executors.Simulator">Simulator</a></code>.</li>
<li>To perform numerical integrations of reduced dynamical systems
describing the macroscopic behavior of the network, use <code><a title="popnet.executors.Integrator" href="#popnet.executors.Integrator">Integrator</a></code>.</li>
</ul>
<p>A reset of the executor is made at the end of the initialization, when
setting the configuration.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>config</code></strong> :&ensp;<code><a title="popnet.structures.Configuration" href="structures.html#popnet.structures.Configuration">Configuration</a></code></dt>
<dd>Configuration used for the experiments.</dd>
</dl>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>config</code></strong> :&ensp;<code><a title="popnet.structures.Configuration" href="structures.html#popnet.structures.Configuration">Configuration</a></code></dt>
<dd>Configuration used for the experiments. See <code><a title="popnet.executors.Executor.config" href="#popnet.executors.Executor.config">Executor.config</a></code>.</dd>
<dt><strong><code>times</code></strong> :&ensp;<code>array_like</code></dt>
<dd>Time. See <code><a title="popnet.executors.Executor.times" href="#popnet.executors.Executor.times">Executor.times</a></code>.</dd>
<dt><strong><code>states</code></strong> :&ensp;<code>array_like</code></dt>
<dd>State of the network with respect to time. See <code><a title="popnet.executors.Executor.states" href="#popnet.executors.Executor.states">Executor.states</a></code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Executor:
    &#34;&#34;&#34;Execute numerical experiments on a network.

    `Executor` is meant to perform numerical experiments to study the dynamics
    on a network split into populations. These experiments are intended to be
    carried out by subclasses of `Executor`.

     - To perform simulations of a stochastic process that rules the
       evolution of the network, use `Simulator`.
     - To perform numerical integrations of reduced dynamical systems
       describing the macroscopic behavior of the network, use `Integrator`.

    A reset of the executor is made at the end of the initialization, when
    setting the configuration.

    Parameters
    ----------
    config : popnet.structures.Configuration
        Configuration used for the experiments.

    Attributes
    ----------
    config : popnet.structures.Configuration
        Configuration used for the experiments. See `Executor.config`.
    times : array_like
        Time. See `Executor.times`.
    states : array_like
        State of the network with respect to time. See `Executor.states`.

    &#34;&#34;&#34;

    def __init__(self, config):
        self.config = config
        self._output_type = None

    @property
    def config(self):
        &#34;&#34;&#34;Configuration used with the executor.

        Configuration defining all parameters used by the executor. It must be
        a `popnet.structures.Configuration` instance, or a
        `popnet.structures.MicroConfiguration` instance if the network must
        have a microscopic structure. If it is set, the executor is reset with
        `Executor.reset`. It cannot be deleted.
        &#34;&#34;&#34;
        return self._config

    @config.setter
    def config(self, new_value):
        if not isinstance(new_value, structures.Configuration):
            raise TypeError(&#39;The configuration used with an executor must be a &#39;
                            &#39;\&#39;Configuration\&#39; instance.&#39;)
        self._config = new_value
        self.reset()

    @property
    def states(self):
        &#34;&#34;&#34;State of the network with respect to time.

        Macroscopic state of the network at each time step. It does not contain
        any relevant data at initialization or right after a reset, but it is
        updated during a call to `Executor.run`. It cannot be manually set nor
        deleted.
        &#34;&#34;&#34;
        return self._states

    @property
    def times(self):
        &#34;&#34;&#34;Time.

        At initialization or with a call to `Executor.reset`, it is set
        according to the executor&#39;s configuration `config`. Specifically, it
        is an array starting at `config.initial_time` and ending at
        `config.final_time`, with an interval of `config.delta` between time
        steps. It cannot be manually set nor deleted.
        &#34;&#34;&#34;
        return self._times

    @property
    def success(self):
        &#34;&#34;&#34;Indicator of success of a numerical experiment.

        Indicator of the success of a numerical experiment. It is set to `None`
        when the executor is reset, and then set to a boolean value after an
        experiment has been performed to indicate whether it was successful or
        not. It cannot be manually set nor deleted.
        &#34;&#34;&#34;
        return self._success

    def close(self):
        &#34;&#34;&#34;Delete all data attributes of the executor.&#34;&#34;&#34;
        del self._config
        del self._states
        del self._times
        del self._success

    def output(self, **kwargs):
        &#34;&#34;&#34;Get the output of the execution.

        Return the results of the numerical experiment.

        Parameters
        ----------
        **kwargs
            Keyword arguments to be passed to the output&#39;s class constructor.

        Returns
        -------
        popnet.graphics.Result
            The output of the experiment. The precise output type depends on the
            experiment executed; see the
            [summary](graphics.html#classes-and-hierarchy) of all
            `popnet.graphics.Result` subclasses for a quick reference giving
            the output type of each case.

        Raises
        ------
        popnet.exceptions.PopNetError
            If the numerical experiment has not been performed yet.
        &#34;&#34;&#34;
        self._check_if_run()
        if self._output_type is None:
            raise PopNetError(
                &#39;PopNet does not know how to output the results of this experi&#39;
                &#39;ment. It might be due to the use of the base class \&#39;Result\&#39; &#39;
                &#39;rather than its subclasses, or to the numerical integration &#39;
                &#39;of an unrecognized dynamical system. It might still be &#39;
                &#39;possible to save the results with Executor.save_output().&#39;)
        return self._output_type(self.config, self._output_states(), 
                                 self._output_times(), **kwargs)

    def reset(self):
        &#34;&#34;&#34;Reset the executor.
        
        Reset the executor to run it again. Sets `Executor.success` to `None`
        and resets `Executor.times` according to the configuration.
        &#34;&#34;&#34;
        self._success = None
        self._times = np.linspace(self.config.initial_time, 
                                  self.config.final_time, 
                                  1 + self.config.iterations)

    def run(self):
        &#34;&#34;&#34;Run the numerical experiment.
        
        This method is abstract and is implemented in subclasses.
        &#34;&#34;&#34;
        raise NotImplementedError(&#39;An executor must implement a \&#39;run\&#39; &#39;
                                  &#39;method.&#39;)

    def save_output(self, name=None, folder=None):
        &#34;&#34;&#34;Save the output of the experiment in a text file.

        Save the output of the numerical experiment in a text file, under the
        name *ID - name.txt*, where *ID* is the ID of the configuration used
        for the experiment and *name* is `name`.

        Parameters
        ----------
        name : str, optional
            Name to give to the saved output. Defaults to `None`, in which case
            it is replaced with a default based on the output class.
        folder : str, optional
            A folder in which the file is saved. If it does not exist in the
            current directory, it is created. Defaults to `None`, in which case
            the file is saved in the current directory.

        Returns
        -------
        name : str
            The name given to the saved output.

        Raises
        ------
        popnet.exceptions.PopNetError
            If the numerical experiment has not been performed yet.
        &#34;&#34;&#34;
        self._check_if_run()
        try:
            name = self._output_type._get_name(name)
        except AttributeError:
            name = &#39;Output&#39;
        filename = _internals._format_filename(folder, self.config.ID, name)
        _internals._make_sure_folder_exists(folder)
        L = self._state_length()
        header = &#39;&#39;.join([f&#39;{X:&lt;16}&#39; for X in self.config._variables[:L]])
        np.savetxt(filename, self._output_states(), fmt=&#39;%+.12f&#39;, header=header)
        return name

    def _check_if_run(self):
        &#34;&#34;&#34;Check if the executor has already run.&#34;&#34;&#34;
        if self.success is None:
            raise PopNetError(&#39;An executor has to run before the results are &#39;
                              &#39;output. Call Executor.run() first.&#39;)

    def _output_states(self):
        &#34;&#34;&#34;States array to output.&#34;&#34;&#34;
        return self.states

    def _output_times(self):
        &#34;&#34;&#34;Times array to output.&#34;&#34;&#34;
        return self.times

    def _state_length(self):
        &#34;&#34;&#34;Length of the macroscopic states.&#34;&#34;&#34;
        raise NotImplementedError(&#39;An executor must give its states\&#39; sizes.&#39;)</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="popnet.executors.Integrator" href="#popnet.executors.Integrator">Integrator</a></li>
<li><a title="popnet.executors.Simulator" href="#popnet.executors.Simulator">Simulator</a></li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="popnet.executors.Executor.config"><code class="name">var <span class="ident">config</span></code></dt>
<dd>
<div class="desc"><p>Configuration used with the executor.</p>
<p>Configuration defining all parameters used by the executor. It must be
a <code><a title="popnet.structures.Configuration" href="structures.html#popnet.structures.Configuration">Configuration</a></code> instance, or a
<code><a title="popnet.structures.MicroConfiguration" href="structures.html#popnet.structures.MicroConfiguration">MicroConfiguration</a></code> instance if the network must
have a microscopic structure. If it is set, the executor is reset with
<code><a title="popnet.executors.Executor.reset" href="#popnet.executors.Executor.reset">Executor.reset()</a></code>. It cannot be deleted.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def config(self):
    &#34;&#34;&#34;Configuration used with the executor.

    Configuration defining all parameters used by the executor. It must be
    a `popnet.structures.Configuration` instance, or a
    `popnet.structures.MicroConfiguration` instance if the network must
    have a microscopic structure. If it is set, the executor is reset with
    `Executor.reset`. It cannot be deleted.
    &#34;&#34;&#34;
    return self._config</code></pre>
</details>
</dd>
<dt id="popnet.executors.Executor.states"><code class="name">var <span class="ident">states</span></code></dt>
<dd>
<div class="desc"><p>State of the network with respect to time.</p>
<p>Macroscopic state of the network at each time step. It does not contain
any relevant data at initialization or right after a reset, but it is
updated during a call to <code><a title="popnet.executors.Executor.run" href="#popnet.executors.Executor.run">Executor.run()</a></code>. It cannot be manually set nor
deleted.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def states(self):
    &#34;&#34;&#34;State of the network with respect to time.

    Macroscopic state of the network at each time step. It does not contain
    any relevant data at initialization or right after a reset, but it is
    updated during a call to `Executor.run`. It cannot be manually set nor
    deleted.
    &#34;&#34;&#34;
    return self._states</code></pre>
</details>
</dd>
<dt id="popnet.executors.Executor.success"><code class="name">var <span class="ident">success</span></code></dt>
<dd>
<div class="desc"><p>Indicator of success of a numerical experiment.</p>
<p>Indicator of the success of a numerical experiment. It is set to <code>None</code>
when the executor is reset, and then set to a boolean value after an
experiment has been performed to indicate whether it was successful or
not. It cannot be manually set nor deleted.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def success(self):
    &#34;&#34;&#34;Indicator of success of a numerical experiment.

    Indicator of the success of a numerical experiment. It is set to `None`
    when the executor is reset, and then set to a boolean value after an
    experiment has been performed to indicate whether it was successful or
    not. It cannot be manually set nor deleted.
    &#34;&#34;&#34;
    return self._success</code></pre>
</details>
</dd>
<dt id="popnet.executors.Executor.times"><code class="name">var <span class="ident">times</span></code></dt>
<dd>
<div class="desc"><p>Time.</p>
<p>At initialization or with a call to <code><a title="popnet.executors.Executor.reset" href="#popnet.executors.Executor.reset">Executor.reset()</a></code>, it is set
according to the executor's configuration <code>config</code>. Specifically, it
is an array starting at <code>config.initial_time</code> and ending at
<code>config.final_time</code>, with an interval of <code>config.delta</code> between time
steps. It cannot be manually set nor deleted.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def times(self):
    &#34;&#34;&#34;Time.

    At initialization or with a call to `Executor.reset`, it is set
    according to the executor&#39;s configuration `config`. Specifically, it
    is an array starting at `config.initial_time` and ending at
    `config.final_time`, with an interval of `config.delta` between time
    steps. It cannot be manually set nor deleted.
    &#34;&#34;&#34;
    return self._times</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="popnet.executors.Executor.close"><code class="name flex">
<span>def <span class="ident">close</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Delete all data attributes of the executor.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def close(self):
    &#34;&#34;&#34;Delete all data attributes of the executor.&#34;&#34;&#34;
    del self._config
    del self._states
    del self._times
    del self._success</code></pre>
</details>
</dd>
<dt id="popnet.executors.Executor.output"><code class="name flex">
<span>def <span class="ident">output</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the output of the execution.</p>
<p>Return the results of the numerical experiment.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Keyword arguments to be passed to the output's class constructor.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="popnet.graphics.Result" href="graphics.html#popnet.graphics.Result">Result</a></code></dt>
<dd>The output of the experiment. The precise output type depends on the
experiment executed; see the
<a href="graphics.html#classes-and-hierarchy">summary</a> of all
<code><a title="popnet.graphics.Result" href="graphics.html#popnet.graphics.Result">Result</a></code> subclasses for a quick reference giving
the output type of each case.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code><a title="popnet.exceptions.PopNetError" href="exceptions.html#popnet.exceptions.PopNetError">PopNetError</a></code></dt>
<dd>If the numerical experiment has not been performed yet.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def output(self, **kwargs):
    &#34;&#34;&#34;Get the output of the execution.

    Return the results of the numerical experiment.

    Parameters
    ----------
    **kwargs
        Keyword arguments to be passed to the output&#39;s class constructor.

    Returns
    -------
    popnet.graphics.Result
        The output of the experiment. The precise output type depends on the
        experiment executed; see the
        [summary](graphics.html#classes-and-hierarchy) of all
        `popnet.graphics.Result` subclasses for a quick reference giving
        the output type of each case.

    Raises
    ------
    popnet.exceptions.PopNetError
        If the numerical experiment has not been performed yet.
    &#34;&#34;&#34;
    self._check_if_run()
    if self._output_type is None:
        raise PopNetError(
            &#39;PopNet does not know how to output the results of this experi&#39;
            &#39;ment. It might be due to the use of the base class \&#39;Result\&#39; &#39;
            &#39;rather than its subclasses, or to the numerical integration &#39;
            &#39;of an unrecognized dynamical system. It might still be &#39;
            &#39;possible to save the results with Executor.save_output().&#39;)
    return self._output_type(self.config, self._output_states(), 
                             self._output_times(), **kwargs)</code></pre>
</details>
</dd>
<dt id="popnet.executors.Executor.reset"><code class="name flex">
<span>def <span class="ident">reset</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Reset the executor.</p>
<p>Reset the executor to run it again. Sets <code><a title="popnet.executors.Executor.success" href="#popnet.executors.Executor.success">Executor.success</a></code> to <code>None</code>
and resets <code><a title="popnet.executors.Executor.times" href="#popnet.executors.Executor.times">Executor.times</a></code> according to the configuration.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset(self):
    &#34;&#34;&#34;Reset the executor.
    
    Reset the executor to run it again. Sets `Executor.success` to `None`
    and resets `Executor.times` according to the configuration.
    &#34;&#34;&#34;
    self._success = None
    self._times = np.linspace(self.config.initial_time, 
                              self.config.final_time, 
                              1 + self.config.iterations)</code></pre>
</details>
</dd>
<dt id="popnet.executors.Executor.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Run the numerical experiment.</p>
<p>This method is abstract and is implemented in subclasses.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run(self):
    &#34;&#34;&#34;Run the numerical experiment.
    
    This method is abstract and is implemented in subclasses.
    &#34;&#34;&#34;
    raise NotImplementedError(&#39;An executor must implement a \&#39;run\&#39; &#39;
                              &#39;method.&#39;)</code></pre>
</details>
</dd>
<dt id="popnet.executors.Executor.save_output"><code class="name flex">
<span>def <span class="ident">save_output</span></span>(<span>self, name=None, folder=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Save the output of the experiment in a text file.</p>
<p>Save the output of the numerical experiment in a text file, under the
name <em>ID - name.txt</em>, where <em>ID</em> is the ID of the configuration used
for the experiment and <em>name</em> is <code>name</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Name to give to the saved output. Defaults to <code>None</code>, in which case
it is replaced with a default based on the output class.</dd>
<dt><strong><code>folder</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>A folder in which the file is saved. If it does not exist in the
current directory, it is created. Defaults to <code>None</code>, in which case
the file is saved in the current directory.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>The name given to the saved output.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code><a title="popnet.exceptions.PopNetError" href="exceptions.html#popnet.exceptions.PopNetError">PopNetError</a></code></dt>
<dd>If the numerical experiment has not been performed yet.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_output(self, name=None, folder=None):
    &#34;&#34;&#34;Save the output of the experiment in a text file.

    Save the output of the numerical experiment in a text file, under the
    name *ID - name.txt*, where *ID* is the ID of the configuration used
    for the experiment and *name* is `name`.

    Parameters
    ----------
    name : str, optional
        Name to give to the saved output. Defaults to `None`, in which case
        it is replaced with a default based on the output class.
    folder : str, optional
        A folder in which the file is saved. If it does not exist in the
        current directory, it is created. Defaults to `None`, in which case
        the file is saved in the current directory.

    Returns
    -------
    name : str
        The name given to the saved output.

    Raises
    ------
    popnet.exceptions.PopNetError
        If the numerical experiment has not been performed yet.
    &#34;&#34;&#34;
    self._check_if_run()
    try:
        name = self._output_type._get_name(name)
    except AttributeError:
        name = &#39;Output&#39;
    filename = _internals._format_filename(folder, self.config.ID, name)
    _internals._make_sure_folder_exists(folder)
    L = self._state_length()
    header = &#39;&#39;.join([f&#39;{X:&lt;16}&#39; for X in self.config._variables[:L]])
    np.savetxt(filename, self._output_states(), fmt=&#39;%+.12f&#39;, header=header)
    return name</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="popnet.executors.Integrator"><code class="flex name class">
<span>class <span class="ident">Integrator</span></span>
<span>(</span><span>system, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Numerical integrators for systems related to Wilson&ndash;Cowan's model.</p>
<p><code><a title="popnet.executors.Integrator" href="#popnet.executors.Integrator">Integrator</a></code> extends <code><a title="popnet.executors.Executor" href="#popnet.executors.Executor">Executor</a></code> to perform numerical integrations of
dynamical systems related to the Wilson&ndash;Cowan model. Numerical
integrations can either be performed with the class
<a href="https://31c8.short.gy/scipy-integrate-ode">ode</a> from SciPy's <code>integrate</code>
module, or with a classical Runge&ndash;Kutta method.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>system</code></strong> :&ensp;<code><a title="popnet.systems.DynamicalSystem" href="systems.html#popnet.systems.DynamicalSystem">DynamicalSystem</a></code></dt>
<dd>Sets the dynamical system to be integrated.</dd>
</dl>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>config</code></strong> :&ensp;<code><a title="popnet.structures.Configuration" href="structures.html#popnet.structures.Configuration">Configuration</a></code></dt>
<dd>Configuration used for the numerical integration. At initialization, it
is automatically taken as that of <code><a title="popnet.executors.Integrator.system" href="#popnet.executors.Integrator.system">Integrator.system</a></code>. See
<code><a title="popnet.executors.Integrator.config" href="#popnet.executors.Executor.config">Integrator.config</a></code>.</dd>
<dt><strong><code>system</code></strong> :&ensp;<code><a title="popnet.systems.DynamicalSystem" href="systems.html#popnet.systems.DynamicalSystem">DynamicalSystem</a></code></dt>
<dd>Dynamical system used for the integration. See <code><a title="popnet.executors.Integrator.system" href="#popnet.executors.Integrator.system">Integrator.system</a></code>.</dd>
<dt><strong><code>times</code></strong> :&ensp;<code>array_like</code></dt>
<dd>Time. See <code><a title="popnet.executors.Integrator.times" href="#popnet.executors.Executor.times">Integrator.times</a></code>.</dd>
<dt><strong><code>states</code></strong> :&ensp;<code>array_like</code></dt>
<dd>State of the network with respect to time. See <code><a title="popnet.executors.Integrator.states" href="#popnet.executors.Executor.states">Integrator.states</a></code>.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>TypeError</code></dt>
<dd>If <code>system</code> is not a <code><a title="popnet.systems.DynamicalSystem" href="systems.html#popnet.systems.DynamicalSystem">DynamicalSystem</a></code> instance.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Integrator(Executor):
    &#34;&#34;&#34;Numerical integrators for systems related to Wilson--Cowan&#39;s model.

    `Integrator` extends `Executor` to perform numerical integrations of
    dynamical systems related to the Wilson--Cowan model. Numerical
    integrations can either be performed with the class
    [ode](https://31c8.short.gy/scipy-integrate-ode) from SciPy&#39;s `integrate`
    module, or with a classical Runge--Kutta method.

    Parameters
    ----------
    system : popnet.systems.DynamicalSystem
        Sets the dynamical system to be integrated.

    Attributes
    ----------
    config : popnet.structures.Configuration
        Configuration used for the numerical integration. At initialization, it
        is automatically taken as that of `Integrator.system`. See
        `Integrator.config`.
    system : popnet.systems.DynamicalSystem
        Dynamical system used for the integration. See `Integrator.system`.
    times : array_like
        Time. See `Integrator.times`.
    states : array_like
        State of the network with respect to time. See `Integrator.states`.

    Raises
    ------
    TypeError
        If `system` is not a `popnet.systems.DynamicalSystem` instance.

    &#34;&#34;&#34;

    def __init__(self, system, **kwargs):
        if not isinstance(system, systems.DynamicalSystem):
            raise TypeError(&#39;The dynamical system associated with an integrator&#39;
                            &#39; must be a \&#39;DynamicalSystem\&#39; instance.&#39;)
        self._system = system
        super().__init__(system.config, **kwargs)
        try:
            output_type = OUTPUT_TYPES[type(self.system)]
        except KeyError:
            warn(&#39;The type of dynamical system you want to integrate is not &#39;
                 &#39;recognized by PopNet. The integration might be possible, &#39;
                 &#39;but it will not be possible to output the results with &#39;
                 &#39;Integrator.output().&#39;, category=PopNetWarning, stacklevel=2)
        else:
            self._output_type = output_type

    @property
    def system(self):
        &#34;&#34;&#34;Dynamical system used for the integration.

        The dynamical system used when performing numerical integrations. It
        is a `popnet.systems.DynamicalSystem` instance associated with the
        same configuration as the integrator. It is set at initialization,
        and afterwards it cannot be manually set nor deleted.
        &#34;&#34;&#34;
        return self._system

    def reset(self):
        &#34;&#34;&#34;Reset the integrator.

        Reset the integrator to run it again. It extends the base class method
        by also resetting `Integrator.states` and by setting the initial state
        to be used in the integration from the configuration.
        &#34;&#34;&#34;
        super().reset()
        self._states = np.zeros((len(self.times), self._state_length()))
        self.states[0] = self.config.initial_state[: self._state_length()]

    def run(self, task, time=&#39;forward&#39;, verbose=False, catch_escape=False,
            backend=&#39;vode&#39;, **kwargs):
        &#34;&#34;&#34;Run a numerical integration.

        Run a numerical integration of the dynamical system using either an
        [ode](https://31c8.short.gy/scipy-integrate-ode) instance from SciPy&#39;s
        `integrate` module, or a classical Runge--Kutta method.

        Parameters
        ----------
        task : {&#39;ode&#39;, &#39;runge-kutta&#39;}, optional
            Choose to integrate with SciPy&#39;s methods or with a classical
            Runge--Kutta method. Defaults to `&#39;ode&#39;`.
        time : {&#39;forward&#39;, &#39;backward&#39;}, optional
            Chooses if the intergration is performed forward of backward in
            time. If the integration is done backward in time, it is done from
            the initial time given by the configuration and for a total time
            interval of the same length as if it was done forward. Defaults to
            `&#39;forward&#39;`.
        verbose : bool, optional
            If `True`, a progression bar is printed to show how much of the
            integration has been performed. Defaults to `False`.
        catch_escape : bool, optional
            If `True`,  the integration stops as soon as a state component
            escapes the interval \\([-1, 1]\\), and the integration is
            considered to have failed. Defaults to `False`.
        backend : {&#39;vode&#39;, &#39;zvode&#39;, &#39;lsoda&#39;, &#39;dopri5&#39;, &#39;dop853&#39;}, optional
            Integrator used with SciPy&#39;s methods. Defaults to `&#39;vode&#39;`. It has
            no effect if `task` is not set to `&#39;ode&#39;`.
        **kwargs
            Keyword arguments to be passed to the `set_integrator` method of
            the `ode` solver. It has no effect if `task` is not set to `&#39;ode&#39;`.

        Warns
        -----
        popnet.exceptions.PopNetWarning
            If the integration fails.
        &#34;&#34;&#34;
        self._success = True
        if time == &#39;forward&#39;:
            def field(t, x): return self._field(t, x)
            def jac(t, x): return self._jac(t, x)
        elif time == &#39;backward&#39;:
            def field(t, x): 
                return - self._field(2 * self.config.initial_time - t, x)
            def jac(t, x): 
                return - self._jac(2 * self.config.initial_time - t, x)
        else:
            raise ValueError(f&#39;Unexpected value {time} for \&#39;time\&#39; keyword. &#39;
                             &#39;Valid values are \&#39;forward\&#39; and \&#39;backward\&#39;.&#39;)
        if verbose:
            def progress(rg): return tqdm(rg)
        else:
            def progress(rg): return rg
        if catch_escape:
            def has_escaped(state): return any(np.abs(state) &gt; 1)
        else:
            def has_escaped(state): return False
        if task == &#39;ode&#39;:
            self._run_ode(field, jac, progress, has_escaped, backend, **kwargs)
        elif task == &#39;runge-kutta&#39;:
            self._run_runge_kutta(field, progress, has_escaped)
        else:
            raise ValueError(f&#39;Unexpected task {task} for Integrator.run(). &#39;
                             &#39;Valid values are \&#39;ode\&#39;  and \&#39;runge-kutta\&#39;.&#39;)
        if time == &#39;backward&#39;:
            self._times = np.flip(2 * self.config.initial_time - self.times)
            self._states = np.flip(self.states, axis=0)
        if not self.success:
            warn(f&#39;Integration failed with configuration {self.config.ID}.&#39;,
                 category=PopNetWarning, stacklevel=2)

    def _field(self, t, Y):
        &#34;&#34;&#34;Vector field.

        Vector field corresponding to the studied dynamical system.

        Parameters
        ----------
        t : float
            Current time.
        Y : array_like
            Current state of the network.

        Returns
        -------
        array_like
            Gradient of the vector field evaluated at time `t` and state `Y`.
        &#34;&#34;&#34;
        return self.system.vector_field(Y)

    def _jac(self, t, Y):
        &#34;&#34;&#34;Jacobian of the `_field` method.

        Jacobian of the vector field corresponding to the studied dynamical
        system. It does not have to be implemented by subclasses.

        Parameters
        ----------
        t : float
            Current time.
        Y : array_like
            Current state of the network.

        Returns
        -------
        array_like
            Jacobian of the vector field evaluated at time `t` and state `Y`.
        &#34;&#34;&#34;
        return self.system.jac(Y)

    def _output_states(self):
        &#34;&#34;&#34;States array to output.&#34;&#34;&#34;
        if isinstance(self.system, systems.WilsonCowanSystem):
            p = len(self.config.network.populations)
            output_states = np.zeros((len(self.times), 2*p))
            output_states[:,:p] = self.states
            for J, popJ in enumerate(self.config.network.populations):
                output_states[:,p+J] = popJ.beta / popJ.gamma * self.states[:,J]
            return output_states
        return super()._output_states()

    def _run_ode(self, field, jac, progress, has_escaped, backend, **kwargs):
        &#34;&#34;&#34;Run a numerical integration with `scipy.integrate.ode`.&#34;&#34;&#34;
        try:
            jac(0, self.states[0])
        except NotImplementedError:
            solver = ode(field)
        else:
            solver = ode(field, jac)
        solver.set_integrator(backend, **kwargs)
        solver.set_initial_value(self.states[0])
        for j in progress(range(1, len(self.times))):
            self.states[j] = solver.integrate(solver.t+self.config.delta)[:]
            if not solver.successful() or has_escaped(self.states[j]):
                self._success = False
                break

    def _run_runge_kutta(self, field, progress, has_escaped):
        &#34;&#34;&#34;Run a numerical integration with a classical Runge--Kutta method.&#34;&#34;&#34;
        for j in progress(range(1, len(self.times))):
            k1 = field(0, self.states[j-1])
            k2 = field(0, self.states[j-1] + self.config.delta * k1 / 2)
            k3 = field(0, self.states[j-1] + self.config.delta * k2 / 2)
            k4 = field(0, self.states[j-1] + self.config.delta * k3)
            slope = (k1 + 2*k2 + 2*k3 + k4) / 6
            self.states[j] = self.states[j-1] + self.config.delta * slope
            if has_escaped(self.states[j]):
                self._success = False
                break

    def _state_length(self):
        &#34;&#34;&#34;Length of the macroscopic states.&#34;&#34;&#34;
        return self.system.dim</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="popnet.executors.Executor" href="#popnet.executors.Executor">Executor</a></li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="popnet.executors.LyapunovExponentsIntegrator" href="#popnet.executors.LyapunovExponentsIntegrator">LyapunovExponentsIntegrator</a></li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="popnet.executors.Integrator.system"><code class="name">var <span class="ident">system</span></code></dt>
<dd>
<div class="desc"><p>Dynamical system used for the integration.</p>
<p>The dynamical system used when performing numerical integrations. It
is a <code><a title="popnet.systems.DynamicalSystem" href="systems.html#popnet.systems.DynamicalSystem">DynamicalSystem</a></code> instance associated with the
same configuration as the integrator. It is set at initialization,
and afterwards it cannot be manually set nor deleted.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def system(self):
    &#34;&#34;&#34;Dynamical system used for the integration.

    The dynamical system used when performing numerical integrations. It
    is a `popnet.systems.DynamicalSystem` instance associated with the
    same configuration as the integrator. It is set at initialization,
    and afterwards it cannot be manually set nor deleted.
    &#34;&#34;&#34;
    return self._system</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="popnet.executors.Integrator.reset"><code class="name flex">
<span>def <span class="ident">reset</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Reset the integrator.</p>
<p>Reset the integrator to run it again. It extends the base class method
by also resetting <code><a title="popnet.executors.Integrator.states" href="#popnet.executors.Executor.states">Integrator.states</a></code> and by setting the initial state
to be used in the integration from the configuration.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset(self):
    &#34;&#34;&#34;Reset the integrator.

    Reset the integrator to run it again. It extends the base class method
    by also resetting `Integrator.states` and by setting the initial state
    to be used in the integration from the configuration.
    &#34;&#34;&#34;
    super().reset()
    self._states = np.zeros((len(self.times), self._state_length()))
    self.states[0] = self.config.initial_state[: self._state_length()]</code></pre>
</details>
</dd>
<dt id="popnet.executors.Integrator.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>self, task, time='forward', verbose=False, catch_escape=False, backend='vode', **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Run a numerical integration.</p>
<p>Run a numerical integration of the dynamical system using either an
<a href="https://31c8.short.gy/scipy-integrate-ode">ode</a> instance from SciPy's
<code>integrate</code> module, or a classical Runge&ndash;Kutta method.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>task</code></strong> :&ensp;<code>{'ode', 'runge-kutta'}</code>, optional</dt>
<dd>Choose to integrate with SciPy's methods or with a classical
Runge&ndash;Kutta method. Defaults to <code>'ode'</code>.</dd>
<dt><strong><code>time</code></strong> :&ensp;<code>{'forward', 'backward'}</code>, optional</dt>
<dd>Chooses if the intergration is performed forward of backward in
time. If the integration is done backward in time, it is done from
the initial time given by the configuration and for a total time
interval of the same length as if it was done forward. Defaults to
<code>'forward'</code>.</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If <code>True</code>, a progression bar is printed to show how much of the
integration has been performed. Defaults to <code>False</code>.</dd>
<dt><strong><code>catch_escape</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If <code>True</code>,
the integration stops as soon as a state component
escapes the interval <span><span class="MathJax_Preview">[-1, 1]</span><script type="math/tex">[-1, 1]</script></span>, and the integration is
considered to have failed. Defaults to <code>False</code>.</dd>
<dt><strong><code>backend</code></strong> :&ensp;<code>{'vode', 'zvode', 'lsoda', 'dopri5', 'dop853'}</code>, optional</dt>
<dd>Integrator used with SciPy's methods. Defaults to <code>'vode'</code>. It has
no effect if <code>task</code> is not set to <code>'ode'</code>.</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Keyword arguments to be passed to the <code>set_integrator</code> method of
the <code>ode</code> solver. It has no effect if <code>task</code> is not set to <code>'ode'</code>.</dd>
</dl>
<h2 id="warns">Warns</h2>
<dl>
<dt><code><a title="popnet.exceptions.PopNetWarning" href="exceptions.html#popnet.exceptions.PopNetWarning">PopNetWarning</a></code></dt>
<dd>If the integration fails.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run(self, task, time=&#39;forward&#39;, verbose=False, catch_escape=False,
        backend=&#39;vode&#39;, **kwargs):
    &#34;&#34;&#34;Run a numerical integration.

    Run a numerical integration of the dynamical system using either an
    [ode](https://31c8.short.gy/scipy-integrate-ode) instance from SciPy&#39;s
    `integrate` module, or a classical Runge--Kutta method.

    Parameters
    ----------
    task : {&#39;ode&#39;, &#39;runge-kutta&#39;}, optional
        Choose to integrate with SciPy&#39;s methods or with a classical
        Runge--Kutta method. Defaults to `&#39;ode&#39;`.
    time : {&#39;forward&#39;, &#39;backward&#39;}, optional
        Chooses if the intergration is performed forward of backward in
        time. If the integration is done backward in time, it is done from
        the initial time given by the configuration and for a total time
        interval of the same length as if it was done forward. Defaults to
        `&#39;forward&#39;`.
    verbose : bool, optional
        If `True`, a progression bar is printed to show how much of the
        integration has been performed. Defaults to `False`.
    catch_escape : bool, optional
        If `True`,  the integration stops as soon as a state component
        escapes the interval \\([-1, 1]\\), and the integration is
        considered to have failed. Defaults to `False`.
    backend : {&#39;vode&#39;, &#39;zvode&#39;, &#39;lsoda&#39;, &#39;dopri5&#39;, &#39;dop853&#39;}, optional
        Integrator used with SciPy&#39;s methods. Defaults to `&#39;vode&#39;`. It has
        no effect if `task` is not set to `&#39;ode&#39;`.
    **kwargs
        Keyword arguments to be passed to the `set_integrator` method of
        the `ode` solver. It has no effect if `task` is not set to `&#39;ode&#39;`.

    Warns
    -----
    popnet.exceptions.PopNetWarning
        If the integration fails.
    &#34;&#34;&#34;
    self._success = True
    if time == &#39;forward&#39;:
        def field(t, x): return self._field(t, x)
        def jac(t, x): return self._jac(t, x)
    elif time == &#39;backward&#39;:
        def field(t, x): 
            return - self._field(2 * self.config.initial_time - t, x)
        def jac(t, x): 
            return - self._jac(2 * self.config.initial_time - t, x)
    else:
        raise ValueError(f&#39;Unexpected value {time} for \&#39;time\&#39; keyword. &#39;
                         &#39;Valid values are \&#39;forward\&#39; and \&#39;backward\&#39;.&#39;)
    if verbose:
        def progress(rg): return tqdm(rg)
    else:
        def progress(rg): return rg
    if catch_escape:
        def has_escaped(state): return any(np.abs(state) &gt; 1)
    else:
        def has_escaped(state): return False
    if task == &#39;ode&#39;:
        self._run_ode(field, jac, progress, has_escaped, backend, **kwargs)
    elif task == &#39;runge-kutta&#39;:
        self._run_runge_kutta(field, progress, has_escaped)
    else:
        raise ValueError(f&#39;Unexpected task {task} for Integrator.run(). &#39;
                         &#39;Valid values are \&#39;ode\&#39;  and \&#39;runge-kutta\&#39;.&#39;)
    if time == &#39;backward&#39;:
        self._times = np.flip(2 * self.config.initial_time - self.times)
        self._states = np.flip(self.states, axis=0)
    if not self.success:
        warn(f&#39;Integration failed with configuration {self.config.ID}.&#39;,
             category=PopNetWarning, stacklevel=2)</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="popnet.executors.Executor" href="#popnet.executors.Executor">Executor</a></b></code>:
<ul class="hlist">
<li><code><a title="popnet.executors.Executor.close" href="#popnet.executors.Executor.close">close</a></code></li>
<li><code><a title="popnet.executors.Executor.config" href="#popnet.executors.Executor.config">config</a></code></li>
<li><code><a title="popnet.executors.Executor.output" href="#popnet.executors.Executor.output">output</a></code></li>
<li><code><a title="popnet.executors.Executor.save_output" href="#popnet.executors.Executor.save_output">save_output</a></code></li>
<li><code><a title="popnet.executors.Executor.states" href="#popnet.executors.Executor.states">states</a></code></li>
<li><code><a title="popnet.executors.Executor.success" href="#popnet.executors.Executor.success">success</a></code></li>
<li><code><a title="popnet.executors.Executor.times" href="#popnet.executors.Executor.times">times</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="popnet.executors.LyapunovExponentsIntegrator"><code class="flex name class">
<span>class <span class="ident">LyapunovExponentsIntegrator</span></span>
<span>(</span><span>system, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Interface to estimate Lyapunov exponents of dynamical systems.</p>
<p>This class extends <code><a title="popnet.executors.Integrator" href="#popnet.executors.Integrator">Integrator</a></code> to compute the Lyapunov exponents along the
integrated solution when calling <code><a title="popnet.executors.LyapunovExponentsIntegrator.run" href="#popnet.executors.LyapunovExponentsIntegrator.run">LyapunovExponentsIntegrator.run()</a></code>. For
this to work, the dynamical system must have a Jacobian matrix implemented,
and an error is raised at initialization if no Jacobian matrix is defined.</p>
<p>The Lyapunov exponents are computed using the discrete QR method described
by Dieci et al. in [1].</p>
<h2 id="references">References</h2>
<ol class="references">
<li>Dieci, Luca, Robert D. Russell, and Erik S. Van Vleck. “On the
Computation of Lyapunov Exponents for Continuous Dynamical Systems.”
<em>SIAM Journal on Numerical Analysis</em> <strong>34</strong> (1), 402&ndash;423 (1997). doi:
<a href="https://doi.org/10.1137/S0036142993247311">10.1137/S0036142993247311</a></li>
</ol></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class LyapunovExponentsIntegrator(Integrator):
    &#34;&#34;&#34;Interface to estimate Lyapunov exponents of dynamical systems.

    This class extends `Integrator` to compute the Lyapunov exponents along the
    integrated solution when calling `LyapunovExponentsIntegrator.run`. For
    this to work, the dynamical system must have a Jacobian matrix implemented,
    and an error is raised at initialization if no Jacobian matrix is defined.

    The Lyapunov exponents are computed using the discrete QR method described
    by Dieci et al. in [1].

    References
    ----------
     1. Dieci, Luca, Robert D. Russell, and Erik S. Van Vleck. “On the
        Computation of Lyapunov Exponents for Continuous Dynamical Systems.”
        *SIAM Journal on Numerical Analysis* **34** (1), 402--423 (1997). doi:
        [10.1137/S0036142993247311](https://doi.org/10.1137/S0036142993247311)

    &#34;&#34;&#34;

    def __init__(self, system, **kwargs):
        super().__init__(system, **kwargs)
        try:
            self.system.jac
        except NotImplementedError as error:
            raise ValueError(&#39;The system must have a Jacobian matrix &#39;
                             &#39;implemented.&#39;) from error
        self._dim = self.system.dim

    @property
    def exponents(self):
        &#34;&#34;&#34;Lyapunov exponents.

        Estimates of the Lyapunov exponents of the dynamical system along the
        integrated solution, once they have been computed. It is automatically
        set during a call to `LyapunovExponentsIntegrator.run`. It cannot be
        manually set nor deleted.
        &#34;&#34;&#34;
        return self._exponents

    def close(self):
        &#34;&#34;&#34;Delete all data attributes of the integrator.&#34;&#34;&#34;
        super().close()
        del self._uptri_diag
        del self._exponents

    def output(self, **kwargs):
        &#34;&#34;&#34;Get the output of the integration.

        Return the results of the numerical integration. It extends the base
        class method by returning the Lyapunov exponents as well as the
        solution.

        Parameters
        ----------
        **kwargs
            Keyword arguments to be passed to the output&#39;s class constructor.

        Returns
        -------
        popnet.graphics.Result
            The output of the integration. The precise output type depends on
            the dynamical system that has been integrated; see the
            [summary](graphics.html#classes-and-hierarchy) of all
            `popnet.graphics.Result` subclasses for a quick reference giving
            the output type of each case.
        array_like
            The Lyapunov exponents.

        Raises
        ------
        popnet.exceptions.PopNetError
            If the numerical integration has not been performed yet.
        &#34;&#34;&#34;
        return super().output(), self.exponents

    def reset(self):
        &#34;&#34;&#34;Reset the integrator.
        
        Reset the integrator to run it again. It extends the base class method
        by also resetting `LyapunovExponentsIntegrator.exponents`.
        &#34;&#34;&#34;
        super().reset()
        self._exponents = None
        self._uptri_diag = np.zeros((len(self.times), self._state_length()))
        self._uptri_diag[0] = np.ones(self._state_length())

    def run(self, time=&#39;forward&#39;, verbose=False, catch_escape=False,
            backend=&#39;vode&#39;, **kwargs):
        &#34;&#34;&#34;Run a numerical integration.

        This method extends the base class method to be able to compute
        Lyapunov exponents. The interface is the same as that of the base
        class method, except that here the integration is only implemented
        using SciPy&#39;s methods.

        See Also
        --------
        Integrator.run
        &#34;&#34;&#34;
        super().run(&#39;ode&#39;, time=time, verbose=verbose,
                    catch_escape=catch_escape, backend=backend, **kwargs)
        logs = np.log(np.abs(self._uptri_diag))
        self._exponents = np.sum(logs, axis=0) / self.times[-1]

    def _field(self, t, Z):
        &#34;&#34;&#34;Vector field.

        Vector field of the differential equation used to estimate Lyapunov
        exponents. See the [Notes](#notes) section below for details.

        Parameters
        ----------
        t : float
            Current time.
        Z : array_like
            Current state of the system.

        Returns
        -------
        array_like
            Gradient of the vectori field evaluated at time `t` and state `Z`.

        Notes
        -----
        This vector field is defined from the vector field *f* of the dynamical
        system `LyapunovExponentsIntegrator.system`. Indeed, to estimate the
        Lyapunov exponents, two differential equations are solved
        simultaneously, namely *x&#39; = f(x)* and *Y&#39; = Df(x(t))Y*, where *Y*
        is a square matrix. The present vector field is simply the
        concatenation of *f* with a flattenned version of its Jacobian matrix.
        &#34;&#34;&#34;
        x = Z[:self._dim]
        Y = np.reshape(Z[self._dim:], (self._dim, self._dim))
        f = np.zeros(self._dim * (self._dim + 1))
        f[:self._dim] = self.system.vector_field(x)
        f[self._dim:] = np.matmul(self.system.jac(x), Y).flatten()
        return f

    def _run_ode(self, field, jac, progress, has_escaped, backend, **kwargs):
        &#34;&#34;&#34;Run a numerical integration with `scipy.integrate.ode`.

        This method overrides the base class method to be able to compute
        Lyapunov exponents.
        &#34;&#34;&#34;
        initial_value = np.concatenate((self.states[0],
                                        np.identity(self._dim).flatten()))
        solver = ode(field)
        solver.set_integrator(backend, **kwargs)
        solver.set_initial_value(initial_value, 0)
        for j in progress(range(len(self.times[:-1]))):
            state = solver.integrate(solver.t + self.config.delta)
            if not solver.successful():
                self._success = False
                break
            self.states[j+1] = state[:self._dim]
            Y = np.reshape(state[self._dim:], (self._dim, self._dim))
            q, r = np.linalg.qr(Y)
            self._uptri_diag[j+1] = np.diag(r)
            initial_value = np.concatenate((state[:self._dim], q.flatten()))
            solver.set_initial_value(initial_value, self.times[j+1])</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="popnet.executors.Integrator" href="#popnet.executors.Integrator">Integrator</a></li>
<li><a title="popnet.executors.Executor" href="#popnet.executors.Executor">Executor</a></li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="popnet.executors.LyapunovExponentsIntegrator.exponents"><code class="name">var <span class="ident">exponents</span></code></dt>
<dd>
<div class="desc"><p>Lyapunov exponents.</p>
<p>Estimates of the Lyapunov exponents of the dynamical system along the
integrated solution, once they have been computed. It is automatically
set during a call to <code><a title="popnet.executors.LyapunovExponentsIntegrator.run" href="#popnet.executors.LyapunovExponentsIntegrator.run">LyapunovExponentsIntegrator.run()</a></code>. It cannot be
manually set nor deleted.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def exponents(self):
    &#34;&#34;&#34;Lyapunov exponents.

    Estimates of the Lyapunov exponents of the dynamical system along the
    integrated solution, once they have been computed. It is automatically
    set during a call to `LyapunovExponentsIntegrator.run`. It cannot be
    manually set nor deleted.
    &#34;&#34;&#34;
    return self._exponents</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="popnet.executors.LyapunovExponentsIntegrator.close"><code class="name flex">
<span>def <span class="ident">close</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Delete all data attributes of the integrator.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def close(self):
    &#34;&#34;&#34;Delete all data attributes of the integrator.&#34;&#34;&#34;
    super().close()
    del self._uptri_diag
    del self._exponents</code></pre>
</details>
</dd>
<dt id="popnet.executors.LyapunovExponentsIntegrator.output"><code class="name flex">
<span>def <span class="ident">output</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the output of the integration.</p>
<p>Return the results of the numerical integration. It extends the base
class method by returning the Lyapunov exponents as well as the
solution.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Keyword arguments to be passed to the output's class constructor.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="popnet.graphics.Result" href="graphics.html#popnet.graphics.Result">Result</a></code></dt>
<dd>The output of the integration. The precise output type depends on
the dynamical system that has been integrated; see the
<a href="graphics.html#classes-and-hierarchy">summary</a> of all
<code><a title="popnet.graphics.Result" href="graphics.html#popnet.graphics.Result">Result</a></code> subclasses for a quick reference giving
the output type of each case.</dd>
<dt><code>array_like</code></dt>
<dd>The Lyapunov exponents.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code><a title="popnet.exceptions.PopNetError" href="exceptions.html#popnet.exceptions.PopNetError">PopNetError</a></code></dt>
<dd>If the numerical integration has not been performed yet.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def output(self, **kwargs):
    &#34;&#34;&#34;Get the output of the integration.

    Return the results of the numerical integration. It extends the base
    class method by returning the Lyapunov exponents as well as the
    solution.

    Parameters
    ----------
    **kwargs
        Keyword arguments to be passed to the output&#39;s class constructor.

    Returns
    -------
    popnet.graphics.Result
        The output of the integration. The precise output type depends on
        the dynamical system that has been integrated; see the
        [summary](graphics.html#classes-and-hierarchy) of all
        `popnet.graphics.Result` subclasses for a quick reference giving
        the output type of each case.
    array_like
        The Lyapunov exponents.

    Raises
    ------
    popnet.exceptions.PopNetError
        If the numerical integration has not been performed yet.
    &#34;&#34;&#34;
    return super().output(), self.exponents</code></pre>
</details>
</dd>
<dt id="popnet.executors.LyapunovExponentsIntegrator.reset"><code class="name flex">
<span>def <span class="ident">reset</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Reset the integrator.</p>
<p>Reset the integrator to run it again. It extends the base class method
by also resetting <code><a title="popnet.executors.LyapunovExponentsIntegrator.exponents" href="#popnet.executors.LyapunovExponentsIntegrator.exponents">LyapunovExponentsIntegrator.exponents</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset(self):
    &#34;&#34;&#34;Reset the integrator.
    
    Reset the integrator to run it again. It extends the base class method
    by also resetting `LyapunovExponentsIntegrator.exponents`.
    &#34;&#34;&#34;
    super().reset()
    self._exponents = None
    self._uptri_diag = np.zeros((len(self.times), self._state_length()))
    self._uptri_diag[0] = np.ones(self._state_length())</code></pre>
</details>
</dd>
<dt id="popnet.executors.LyapunovExponentsIntegrator.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>self, time='forward', verbose=False, catch_escape=False, backend='vode', **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Run a numerical integration.</p>
<p>This method extends the base class method to be able to compute
Lyapunov exponents. The interface is the same as that of the base
class method, except that here the integration is only implemented
using SciPy's methods.</p>
<h2 id="see-also">See Also</h2>
<p><code><a title="popnet.executors.Integrator.run" href="#popnet.executors.Integrator.run">Integrator.run()</a></code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run(self, time=&#39;forward&#39;, verbose=False, catch_escape=False,
        backend=&#39;vode&#39;, **kwargs):
    &#34;&#34;&#34;Run a numerical integration.

    This method extends the base class method to be able to compute
    Lyapunov exponents. The interface is the same as that of the base
    class method, except that here the integration is only implemented
    using SciPy&#39;s methods.

    See Also
    --------
    Integrator.run
    &#34;&#34;&#34;
    super().run(&#39;ode&#39;, time=time, verbose=verbose,
                catch_escape=catch_escape, backend=backend, **kwargs)
    logs = np.log(np.abs(self._uptri_diag))
    self._exponents = np.sum(logs, axis=0) / self.times[-1]</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="popnet.executors.Integrator" href="#popnet.executors.Integrator">Integrator</a></b></code>:
<ul class="hlist">
<li><code><a title="popnet.executors.Integrator.config" href="#popnet.executors.Executor.config">config</a></code></li>
<li><code><a title="popnet.executors.Integrator.save_output" href="#popnet.executors.Executor.save_output">save_output</a></code></li>
<li><code><a title="popnet.executors.Integrator.states" href="#popnet.executors.Executor.states">states</a></code></li>
<li><code><a title="popnet.executors.Integrator.success" href="#popnet.executors.Executor.success">success</a></code></li>
<li><code><a title="popnet.executors.Integrator.system" href="#popnet.executors.Integrator.system">system</a></code></li>
<li><code><a title="popnet.executors.Integrator.times" href="#popnet.executors.Executor.times">times</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="popnet.executors.SimpleSimulator"><code class="flex name class">
<span>class <span class="ident">SimpleSimulator</span></span>
<span>(</span><span>config, act='step', **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Perform single simulations of a stochastic process on a network.</p>
<p><code><a title="popnet.executors.SimpleSimulator" href="#popnet.executors.SimpleSimulator">SimpleSimulator</a></code> extends <code><a title="popnet.executors.Simulator" href="#popnet.executors.Simulator">Simulator</a></code> to ease the task of running single
simulations of a stochastic process. It has dedicated methods to run
simulations and output a <code><a title="popnet.graphics.Trajectory" href="graphics.html#popnet.graphics.Trajectory">Trajectory</a></code> instance. Its data
attributes are the same as in the base class.</p>
<p>The initialization parameters are the same as in the base class.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SimpleSimulator(Simulator):
    &#34;&#34;&#34;Perform single simulations of a stochastic process on a network.

    `SimpleSimulator` extends `Simulator` to ease the task of running single
    simulations of a stochastic process. It has dedicated methods to run
    simulations and output a `popnet.graphics.Trajectory` instance. Its data
    attributes are the same as in the base class.

    The initialization parameters are the same as in the base class.

    &#34;&#34;&#34;

    def run(self, method=&#39;direct&#39;, verbose=False):
        &#34;&#34;&#34;Run a simulation.

        Run a simulation to obtain a possible trajectory of a stochastic
        process that rules the evolution of the network&#39;s state. To obtain this
        trajectory, we use the Doob--Gillespie algorithm, either with the direct
        or with the first reaction method. See `Simulator.single_run` for more
        details about the Doob--Gillespie algorithm.

        Parameters
        ----------
        method : {&#39;direct&#39;, &#39;first reaction&#39;}, optional
            Chooses which method is used to perform the Monte Carlo step in the
            Doob--Gillespie algorithm. Defaults to `&#39;direct&#39;`.
        verbose : bool, optional
            If `True`, the current time is printed at each iteration. Defaults
            to `False`.

        Raises
        ------
        popnet.exceptions.PopNetError
            If the length of the microscopic initial state is different from
            the network&#39;s size.
        ValueError
            If an unexpected value is passed to `method`.
        &#34;&#34;&#34;
        self._check_sizes()
        if method == &#39;direct&#39;:
            def do_step(rng,t,ns,r): return self._direct_method(rng,t,ns,r)
        elif method == &#39;first reaction&#39;:
            def do_step(rng,t,ns,r): return self._first_reaction_method(rng,t,ns,r)
        else:
            raise ValueError(f&#39;Unexpected method {method}. Valid values are &#39;
                             &#39;\&#39;direct\&#39; and \&#39;first reaction\&#39;.&#39;)
        if verbose:
            def iterate(do_step, rng, t, x):
                print(f&#39;t = {t:&lt;.2f}&#39;, end=&#39;\r&#39;)
                return self._iterate(do_step, rng, t, x)
        else:
            def iterate(do_step, rng, t, x): 
                return self._iterate(do_step, rng, t, x)
        self.single_run(np.random.default_rng(), do_step, iterate)
        if verbose:
            print(10*&#39; &#39;, end=&#39;\r&#39;)
            print(&#39;Done!&#39;)
        self._success = True

    def save_output(self, name=None, folder=None):
        &#34;&#34;&#34;Save the simulation&#39;s output to a text file.

        Extends the base class method by saving additionally the times at which
        transitions occur. This is done by saving the array
        `Simulator.transition_times` under *ID - name (times).txt*, where *ID*
        is the ID of the configuration used for the simulation, and *name* is
        `name`.

        Parameters
        ----------
        name : str, optional
            Name to give to the saved output. Defaults to `None`, in which case
            it is replaced with `&#39;Trajectory&#39;`.
        folder : str, optional
            A folder in which the files are saved. If it does not exist in the
            current directory, it is created. Defaults to `None`, in which case
            the files are saved in the current directory.

        Returns
        -------
        name : str
            Name given to the saved output.

        Raises
        ------
        popnet.exceptions.PopNetError
            If the simulation has not been performed yet.
        &#34;&#34;&#34;
        name = super().save_output(name=name, folder=folder)
        filename = _internals._format_filename(folder, self.config.ID,
                                               f&#39;{name} (times)&#39;)
        np.savetxt(filename, self.transition_times, fmt=&#39;%+.12f&#39;)
        return name

    def _output_times(self):
        &#34;&#34;&#34;Times array to output.&#34;&#34;&#34;
        return self.transition_times</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="popnet.executors.Simulator" href="#popnet.executors.Simulator">Simulator</a></li>
<li><a title="popnet.executors.Executor" href="#popnet.executors.Executor">Executor</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="popnet.executors.SimpleSimulator.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>self, method='direct', verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Run a simulation.</p>
<p>Run a simulation to obtain a possible trajectory of a stochastic
process that rules the evolution of the network's state. To obtain this
trajectory, we use the Doob&ndash;Gillespie algorithm, either with the direct
or with the first reaction method. See <code><a title="popnet.executors.Simulator.single_run" href="#popnet.executors.Simulator.single_run">Simulator.single_run()</a></code> for more
details about the Doob&ndash;Gillespie algorithm.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>method</code></strong> :&ensp;<code>{'direct', 'first reaction'}</code>, optional</dt>
<dd>Chooses which method is used to perform the Monte Carlo step in the
Doob&ndash;Gillespie algorithm. Defaults to <code>'direct'</code>.</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If <code>True</code>, the current time is printed at each iteration. Defaults
to <code>False</code>.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code><a title="popnet.exceptions.PopNetError" href="exceptions.html#popnet.exceptions.PopNetError">PopNetError</a></code></dt>
<dd>If the length of the microscopic initial state is different from
the network's size.</dd>
<dt><code>ValueError</code></dt>
<dd>If an unexpected value is passed to <code>method</code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run(self, method=&#39;direct&#39;, verbose=False):
    &#34;&#34;&#34;Run a simulation.

    Run a simulation to obtain a possible trajectory of a stochastic
    process that rules the evolution of the network&#39;s state. To obtain this
    trajectory, we use the Doob--Gillespie algorithm, either with the direct
    or with the first reaction method. See `Simulator.single_run` for more
    details about the Doob--Gillespie algorithm.

    Parameters
    ----------
    method : {&#39;direct&#39;, &#39;first reaction&#39;}, optional
        Chooses which method is used to perform the Monte Carlo step in the
        Doob--Gillespie algorithm. Defaults to `&#39;direct&#39;`.
    verbose : bool, optional
        If `True`, the current time is printed at each iteration. Defaults
        to `False`.

    Raises
    ------
    popnet.exceptions.PopNetError
        If the length of the microscopic initial state is different from
        the network&#39;s size.
    ValueError
        If an unexpected value is passed to `method`.
    &#34;&#34;&#34;
    self._check_sizes()
    if method == &#39;direct&#39;:
        def do_step(rng,t,ns,r): return self._direct_method(rng,t,ns,r)
    elif method == &#39;first reaction&#39;:
        def do_step(rng,t,ns,r): return self._first_reaction_method(rng,t,ns,r)
    else:
        raise ValueError(f&#39;Unexpected method {method}. Valid values are &#39;
                         &#39;\&#39;direct\&#39; and \&#39;first reaction\&#39;.&#39;)
    if verbose:
        def iterate(do_step, rng, t, x):
            print(f&#39;t = {t:&lt;.2f}&#39;, end=&#39;\r&#39;)
            return self._iterate(do_step, rng, t, x)
    else:
        def iterate(do_step, rng, t, x): 
            return self._iterate(do_step, rng, t, x)
    self.single_run(np.random.default_rng(), do_step, iterate)
    if verbose:
        print(10*&#39; &#39;, end=&#39;\r&#39;)
        print(&#39;Done!&#39;)
    self._success = True</code></pre>
</details>
</dd>
<dt id="popnet.executors.SimpleSimulator.save_output"><code class="name flex">
<span>def <span class="ident">save_output</span></span>(<span>self, name=None, folder=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Save the simulation's output to a text file.</p>
<p>Extends the base class method by saving additionally the times at which
transitions occur. This is done by saving the array
<code><a title="popnet.executors.Simulator.transition_times" href="#popnet.executors.Simulator.transition_times">Simulator.transition_times</a></code> under <em>ID - name (times).txt</em>, where <em>ID</em>
is the ID of the configuration used for the simulation, and <em>name</em> is
<code>name</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Name to give to the saved output. Defaults to <code>None</code>, in which case
it is replaced with <code>'Trajectory'</code>.</dd>
<dt><strong><code>folder</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>A folder in which the files are saved. If it does not exist in the
current directory, it is created. Defaults to <code>None</code>, in which case
the files are saved in the current directory.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name given to the saved output.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code><a title="popnet.exceptions.PopNetError" href="exceptions.html#popnet.exceptions.PopNetError">PopNetError</a></code></dt>
<dd>If the simulation has not been performed yet.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_output(self, name=None, folder=None):
    &#34;&#34;&#34;Save the simulation&#39;s output to a text file.

    Extends the base class method by saving additionally the times at which
    transitions occur. This is done by saving the array
    `Simulator.transition_times` under *ID - name (times).txt*, where *ID*
    is the ID of the configuration used for the simulation, and *name* is
    `name`.

    Parameters
    ----------
    name : str, optional
        Name to give to the saved output. Defaults to `None`, in which case
        it is replaced with `&#39;Trajectory&#39;`.
    folder : str, optional
        A folder in which the files are saved. If it does not exist in the
        current directory, it is created. Defaults to `None`, in which case
        the files are saved in the current directory.

    Returns
    -------
    name : str
        Name given to the saved output.

    Raises
    ------
    popnet.exceptions.PopNetError
        If the simulation has not been performed yet.
    &#34;&#34;&#34;
    name = super().save_output(name=name, folder=folder)
    filename = _internals._format_filename(folder, self.config.ID,
                                           f&#39;{name} (times)&#39;)
    np.savetxt(filename, self.transition_times, fmt=&#39;%+.12f&#39;)
    return name</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="popnet.executors.Simulator" href="#popnet.executors.Simulator">Simulator</a></b></code>:
<ul class="hlist">
<li><code><a title="popnet.executors.Simulator.activation_rates" href="#popnet.executors.Simulator.activation_rates">activation_rates</a></code></li>
<li><code><a title="popnet.executors.Simulator.activation_rates_shape" href="#popnet.executors.Simulator.activation_rates_shape">activation_rates_shape</a></code></li>
<li><code><a title="popnet.executors.Simulator.calcium_output" href="#popnet.executors.Simulator.calcium_output">calcium_output</a></code></li>
<li><code><a title="popnet.executors.Simulator.close" href="#popnet.executors.Simulator.close">close</a></code></li>
<li><code><a title="popnet.executors.Simulator.config" href="#popnet.executors.Executor.config">config</a></code></li>
<li><code><a title="popnet.executors.Simulator.micro_output" href="#popnet.executors.Simulator.micro_output">micro_output</a></code></li>
<li><code><a title="popnet.executors.Simulator.micro_states" href="#popnet.executors.Simulator.micro_states">micro_states</a></code></li>
<li><code><a title="popnet.executors.Simulator.output" href="#popnet.executors.Executor.output">output</a></code></li>
<li><code><a title="popnet.executors.Simulator.reset" href="#popnet.executors.Simulator.reset">reset</a></code></li>
<li><code><a title="popnet.executors.Simulator.single_run" href="#popnet.executors.Simulator.single_run">single_run</a></code></li>
<li><code><a title="popnet.executors.Simulator.states" href="#popnet.executors.Executor.states">states</a></code></li>
<li><code><a title="popnet.executors.Simulator.success" href="#popnet.executors.Executor.success">success</a></code></li>
<li><code><a title="popnet.executors.Simulator.times" href="#popnet.executors.Executor.times">times</a></code></li>
<li><code><a title="popnet.executors.Simulator.transition_times" href="#popnet.executors.Simulator.transition_times">transition_times</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="popnet.executors.Simulator"><code class="flex name class">
<span>class <span class="ident">Simulator</span></span>
<span>(</span><span>config, act='step', **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Numerical simulator of the stochastic process on a network.</p>
<p><code><a title="popnet.executors.Simulator" href="#popnet.executors.Simulator">Simulator</a></code> extends <code><a title="popnet.executors.Executor" href="#popnet.executors.Executor">Executor</a></code> to perform numerical simulations of
stochastic processes on a network that can be macroscopically approximated
by the Wilson&ndash;Cowan model.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>config</code></strong> :&ensp;<code><a title="popnet.structures.MicroConfiguration" href="structures.html#popnet.structures.MicroConfiguration">MicroConfiguration</a></code></dt>
<dd>Sets the configuration used for simulations.</dd>
<dt><strong><code>act</code></strong> :&ensp;<code>{'step', 'sigmoid'}</code>, optional</dt>
<dd>Sets the shape of the activation rate of a neuron. Defaults to <code>step</code>.</dd>
</dl>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>config</code></strong> :&ensp;<code><a title="popnet.structures.MicroConfiguration" href="structures.html#popnet.structures.MicroConfiguration">MicroConfiguration</a></code></dt>
<dd>Configuration used for the simulations. See <code><a title="popnet.executors.Simulator.config" href="#popnet.executors.Executor.config">Simulator.config</a></code>.</dd>
<dt><strong><code>states</code></strong>, <strong><code>times</code></strong> :&ensp;<code>array_like</code></dt>
<dd>Macroscopic state of the network with respect to time. See
<code><a title="popnet.executors.Simulator.states" href="#popnet.executors.Executor.states">Simulator.states</a></code> and <code><a title="popnet.executors.Simulator.times" href="#popnet.executors.Executor.times">Simulator.times</a></code>.</dd>
<dt><strong><code>micro_states</code></strong>, <strong><code>transition_times</code></strong> :&ensp;<code>array_like</code></dt>
<dd>Microscopic state of the network with respect to time. See
<code><a title="popnet.executors.Simulator.micro_states" href="#popnet.executors.Simulator.micro_states">Simulator.micro_states</a></code> and <code><a title="popnet.executors.Simulator.transition_times" href="#popnet.executors.Simulator.transition_times">Simulator.transition_times</a></code>.</dd>
<dt><strong><code>activation_rates</code></strong> :&ensp;<code>list</code></dt>
<dd>Activation rates of the neurons of the network. See
<code><a title="popnet.executors.Simulator.activation_rates" href="#popnet.executors.Simulator.activation_rates">Simulator.activation_rates</a></code>.</dd>
<dt><strong><code>activation_rates_shape</code></strong> :&ensp;<code>{'step', 'sigmoid'}</code></dt>
<dd>Describes the shape of the activation rate of neurons of the network.
See <code><a title="popnet.executors.Simulator.activation_rates_shape" href="#popnet.executors.Simulator.activation_rates_shape">Simulator.activation_rates_shape</a></code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Simulator(Executor):
    &#34;&#34;&#34;Numerical simulator of the stochastic process on a network.

    `Simulator` extends `Executor` to perform numerical simulations of
    stochastic processes on a network that can be macroscopically approximated
    by the Wilson--Cowan model.

    Parameters
    ----------
    config : popnet.structures.MicroConfiguration
        Sets the configuration used for simulations.
    act : {&#39;step&#39;, &#39;sigmoid&#39;}, optional
        Sets the shape of the activation rate of a neuron. Defaults to `step`.

    Attributes
    ----------
    config : popnet.structures.MicroConfiguration
        Configuration used for the simulations. See `Simulator.config`.
    states, times : array_like
        Macroscopic state of the network with respect to time. See
        `Simulator.states` and `Simulator.times`.
    micro_states, transition_times : array_like
        Microscopic state of the network with respect to time. See
        `Simulator.micro_states` and `Simulator.transition_times`.
    activation_rates : list
        Activation rates of the neurons of the network. See
        `Simulator.activation_rates`.
    activation_rates_shape : {&#39;step&#39;, &#39;sigmoid&#39;}
        Describes the shape of the activation rate of neurons of the network.
        See `Simulator.activation_rates_shape`.

    &#34;&#34;&#34;

    def __init__(self, config, act=&#39;step&#39;, **kwargs):
        self.activation_rates_shape = act
        super().__init__(config, **kwargs)
        try:
            output_type = OUTPUT_TYPES[type(self)]
        except KeyError:
            warn(&#39;The type of simulator you want to run is not recognized by &#39;
                 &#39;PopNet. The simulation might be possible if a \&#39;run\&#39; method &#39;
                 &#39;is implemented, but it will not be possible to output the &#39;
                 &#39;results with Simulator.output().&#39;, category=PopNetWarning,
                 stacklevel=2)
        else:
            self._output_type = output_type

    @Executor.config.setter
    def config(self, new_value):
        if not isinstance(new_value, structures.MicroConfiguration):
            raise TypeError(&#39;The configuration used with a simulator must be a &#39;
                            &#39;\&#39;MicroConfiguration\&#39; instance.&#39;)
        self._config = new_value
        self.reset()

    @property
    def micro_states(self):
        &#34;&#34;&#34;Microscopic state of the network with respect to time.

        Microscopic state of the network at each time step in
        `Simulator.transition_times`. It does not contain any relevant data at
        initialization or right after a reset, but it is updated during a call
        to `Simulator.run`. It cannot be manually set nor deleted.
        &#34;&#34;&#34;
        return self._micro_states

    @property
    def transition_times(self):
        &#34;&#34;&#34;Time.

        Times at which transitions have occurred for a given trajectory. Unlike
        `Simulator.times`, it is not set according to the configuration used,
        but rather updated stochastically during a call to `Simulator.run`. It
        does not contain any relevant data at initialization or right after a
        reset. It cannot be manually set nor deleted.
        &#34;&#34;&#34;
        return self._transition_times

    @property
    def activation_rates(self):
        &#34;&#34;&#34;Activation rates of the neurons.

        List of functions representing the activation rates of the network&#39;s
        neurons. `activation_rates[j](x)` gives the activation rate of the
        *j*th neuron of the network if the state of the whole network is `x`.
        It cannot be manually set nor deleted.
        &#34;&#34;&#34;
        return self._activation_rates

    @property
    def activation_rates_shape(self):
        &#34;&#34;&#34;Shape of the activation rates.

        Shape of the activation rate of a single neuron of the network as a
        function of its input. The only valid values are:

         - `&#39;step&#39;`. In that case, a neuron&#39;s activation rate is a step
           function going from zero to `popnet.structures.MicroNetwork.alpha`
           at its threshold `popnet.structures.MicroNetwork.theta`.
         - `&#39;sigmoid&#39;`. In that case, a neuron&#39;s activation rate is the
           logistic function `popnet.structures.Population.F` of the population
           to which it belongs.

        It can only be set to one of the above values, and it cannot be
        manually deleted.

        !!! note
            After initialization, a change in the value of this property will
            only have an effect after a reset of the simulator with
            `Simulator.reset`.
        &#34;&#34;&#34;
        return self._activation_rates_shape

    @activation_rates_shape.setter
    def activation_rates_shape(self, new_value):
        valid_values = [&#39;step&#39;, &#39;sigmoid&#39;]
        if new_value not in valid_values:
            raise ValueError(f&#39;Unexpected value {new_value} for the shape of &#39;
                             &#39;the activation rates. Valid values are &#39;
                             f&#39;{valid_values}.&#39;)
        self._activation_rates_shape = new_value

    def calcium_output(self, indices=None, growth_rate=None, decay_rate=None):
        &#34;&#34;&#34;Get the calcium concentration in neural cells.

        Get the concentration of calcium in neural cells with respect to time. 

        Parameters
        ----------
        indices : int or array_like, optional
            Indices of neurons for which to get the calcium concentration.
            Defaults to `None`, in which case the calcium concentration is given
            for every neuron of the network.
        growth_rate : float, optional
            Initial growth rate of the calcium concentration. It must be
            positive. Defaults to `None`, in which case it is replaced with the
            inverse of the configuration&#39;s time step
            `popnet.structures.Configuration.delta`.
        decay_rate : float, optional
            Decay rate of the calcium concentration. It must be positive, and it
            should be much smaller than the initial growth rate. Defaults to
            `None`, in which case it is replaced with five percent of the
            initial growth rate.

        Returns
        -------
        array_like
            Calcium concentration with respect to time for every requested
            neuron, with neurons along the first axis and time along the second.
            If a single neuron was requested, it is one-dimensional.

        Raises
        ------
        ValueError
            If `indices` is not a valid list of indices for neurons of the
            network.
        &#34;&#34;&#34;
        if growth_rate is None:
            growth_rate = 1 / self.config.delta
        if decay_rate is None:
            decay_rate = .05 * growth_rate
        if isinstance(indices, int):
            return self._get_calcium_output(indices, growth_rate, decay_rate)
        valid_indices = np.arange(self.config.network.size())
        if indices is None:
            indices = valid_indices
        try:
            valid_indices[indices]
        except IndexError as error:
            raise ValueError(f&#39;{indices} is not a valid list of indices for &#39;
                             &#39;neurons of the network.&#39;) from error
        calcium = np.zeros((N := len(indices), len(self.transition_times)))
        for j in range(N):
            calcium[j,:] = self._get_calcium_output(j, growth_rate, decay_rate)
        return calcium

    def close(self):
        &#34;&#34;&#34;Delete all data attributes of the simulator.&#34;&#34;&#34;
        super().close()
        del self._micro_states
        del self._transition_times

    def micro_output(self, fmt=&#39;ternary&#39;):
        &#34;&#34;&#34;Get the simulation&#39;s microscopic output.
        
        Get the microscopic state of the network with respect to time after
        a simulation was performed.

        Parameters
        ----------
        fmt : {&#39;binary&#39;, &#39;ternary&#39;, &#39;calcium&#39;}, optional
            Format of the neurons&#39; states. If `&#39;ternary&#39;`, a neuron&#39;s state can
            take the values `1`, `1j` or `0`, associated with the *active*,
            *refractory* and *sensitive* states respectively. If `&#39;binary&#39;`, a
            neuron&#39;s state can take the values `1` or `0`, where `1` is still
            associated with the active state, but `0` is rather associated with
            any non-active state (sensitive or refractory). If `&#39;calcium&#39;`,
            the returned output is the default given by
            `Simulator.calcium_output`. Defaults to `&#39;ternary&#39;`.

        Returns
        -------
        array_like
            Microscopic state of the network with respect to time.

        Raises
        ------
        ValueError
            If `fmt` is passed an unexpected value.
        &#34;&#34;&#34;
        self._check_if_run()
        if fmt == &#39;ternary&#39;:
            return self.micro_states
        if fmt == &#39;binary&#39;:
            return np.real(self.micro_states)
        if fmt == &#39;calcium&#39;:
            return self.calcium_output()
        raise ValueError(f&#39;Unexpected format {fmt} for microscopic states. Valid&#39;
                         &#39; values are \&#39;ternary\&#39;, \&#39;binary\&#39; and \&#39;calcium\&#39;.&#39;)

    def reset(self):
        &#34;&#34;&#34;Reset the simulator.

        Reset the simulator to run it again. It extends the base class method
        by also resetting the arrays `Simulator.states`,
        `Simulator.micro_states` and `Simulator.transition_times`, by
        resetting the activation rate functions, and by resetting the
        microscopic initial state to be used in the simulation from the
        configuration.
        &#34;&#34;&#34;
        super().reset()
        self._states = None
        self._transition_times = [self.config.initial_time]
        self._micro_states = [self.config.micro_initial_state.copy()]
        self._reset_activation_rates()

    def single_run(self, rng, do_step, iterate):
        &#34;&#34;&#34;Run a single simulation.

        Run a simulation to obtain a possible trajectory of the stochastic
        process which describes the evolution of the network. To obtain this
        trajectory, the Doob--Gillespie algorithm is used either with the
        direct method or with the first reaction method. See the
        [Notes](#simulator-single-run-notes) section below for more details
        about the algorithm.

        !!! note
            The recommended way to perform simulations of the stochastic process
            is *not* to use this method, but rather to use `SimpleSimulator.run`
            or `ChainSimulator.run`, which both use it internally.

        Parameters
        ----------
        rng : numpy.random.Generator
            A random number generator.
        do_step : callable
            Dictates how to do the Monte Carlo step of the Doob--Gillespie
            algorithm. It is a function to be passed to `iterate`. It expects
            as inputs, in order: `rng`, the current time `t`, an array of the
            next possible network states, and an array of the corresponding
            transition rates. It should return the index of the next network
            state and the time interval between `t` and the next transition.
        iterate : callable
            Dictates how a complete iteration of the simulation is performed.
            This includes the Monte Carlo step as well as all other tasks that
            should be done at each time step. It expects as inputs, in order:
            `do_step`, `rng`, `t` and `x`, where `t` and `x` are the current
            time and network state. It should return the next time and network
            state.

        Notes {#simulator-single-run-notes}
        -----
        From the microscopic point of view, the evolution of the state of the
        whole network is described by a stochastic process. The simulation run
        by this method outputs a possible trajectory of this stochastic process,
        using the Doob--Gillespie algorithm, based on results of Doob [1,2] and
        popularized by Gillespie in [3]. To pass from a state to another, the
        idea is first to find all of the states to which the network can go
        from the current one, with the corresponding transition rates. This
        information is in fact sufficient to determine the distribution of the
        time at which the next transition occurs and which one will occur.

        In [3], Gillespie introduces two methods, called the *direct* and
        *first reaction* methods respectively, to choose the time interval until
        the next transition and the next state of the system.

         - **Direct method.** First, the total transition rate out of the
           current state is computed, and a time interval until the next
           transition is taken randomly knowing that it is exponentially
           distributed with parameter equal to this total out rate. Then a next
           state is chosen randomly knowing that the probability of going to a
           given other state is proportional to the corresponding transition
           rate.

         - **First reaction method.** For every possible next state, a time at
           which the corresponding transition could occur is randomly generated,
           knowing that this time is exponentially distributed with parameter
           equal to the transition rate. The transition that should occur first
           is chosen, and the state is updated accordingly.

        References
        ----------
         1. Doob, J. L. “Topics in the Theory of Markoff Chains.” *Transactions
            of the American Mathematical Society* **52**, 37--64 (1942).
            doi: [10.2307/1990152](https://doi.org/10.2307/1990152).
         2. Doob, J. L. “Markoff Chains--Denumerable Case.” *Transactions of the
            American Mathematical Society* **58**, 455--473 (1945).
            doi: [10.2307/1990339](https://doi.org/10.2307/1990339).
         3. Gillespie, D. T. “A General Method for Numerically Simulating the
            Stochastic Time Evolution of Coupled Chemical Reactions.” *Journal
            of Computational Physics* **22**, 403--434 (1976). doi:
            [10.1016/0021-9991(76)90041-3](
            https://doi.org/10.1016/0021-9991(76)90041-3).
        &#34;&#34;&#34;
        t = self.transition_times[0]
        x = self.micro_states[0]
        while t &lt; self.config.final_time:
            t, x = iterate(do_step, rng, t, x)
        self._micro_states = np.array(self.micro_states)
        self._transition_times = np.array(self.transition_times)
        self._update_states()

    def _check_sizes(self):
        &#34;&#34;&#34;Check the consistency of the network&#39;s size and the initial state.&#34;&#34;&#34;
        if len(self.config.micro_initial_state) != self.config.network.size():
            raise PopNetError(&#39;The size of the network has changed since the &#39;
                              &#39;microscopic initial state was set. Reset the &#39;
                              &#39;simulator before to run it. The network\&#39;s &#39;
                              &#39;parameters might also have to be reset.&#39;)

    def _direct_method(self, rng, t, next_states, rates):
        &#34;&#34;&#34;Obtain the next state and time from the direct method.&#34;&#34;&#34;
        out_rate = np.sum(rates)
        threshold_rate = rng.random() * out_rate
        j = 0
        sum_of_rates = rates[0]
        while sum_of_rates &lt; threshold_rate:
            sum_of_rates += rates[j+1]
            j += 1
        return j, (1 / out_rate) * np.log(1 / rng.random())

    def _first_reaction_method(self, rng, t, next_states, rates):
        &#34;&#34;&#34;Obtain the next state and time from the first reaction method.&#34;&#34;&#34;
        next_times = (1 / rates) * np.log(1 / rng.random(len(rates)))
        j = np.argmin(next_times)
        return j, next_times[j]

    def _get_calcium_output(self, j, growth_rate, decay_rate):
        &#34;&#34;&#34;Get the calcium concentration in neuron *j* with respect to time.&#34;&#34;&#34;
        binary_state = np.real(self.micro_states[:,j])
        all_activation_indices = np.nonzero(binary_state)[0]
        activation_indices = [k for i,k in enumerate(all_activation_indices)
                              if all_activation_indices[i-1] != k-1]
        calcium = np.zeros((len(activation_indices), 
                            len(self.transition_times)))
        for k, activation_index in enumerate(activation_indices):
            t = self.transition_times[activation_index:] 
            t0 = self.transition_times[activation_index]
            calcium[k,activation_index:] = ((1 - np.exp(-growth_rate * (t-t0)))
                                                * np.exp(-decay_rate * (t-t0)))
        calcium = np.sum(calcium, axis=0)
        return calcium

    def _iterate(self, do_step, rng, t, x):
        &#34;&#34;&#34;Perform a single iteration of a simulation.

        Perform a single iteration of a simulation. 

        Parameters
        ----------
        do_step : function
            Dictates how the Monte Carlo step of Gillespie&#39;s algorithm.
        rng : Generator
            Random number generator.
        t : float
            Current time step.
        x : array_like
            Current state of the network.

        Returns
        -------
        float
            Next time step.
        array_like
            Next state of the network.
        &#34;&#34;&#34;
        next_states, rates = self._next_states_and_rates(x)
        j, time_interval = do_step(rng, t, next_states, rates)
        x = next_states[j].copy()
        t += time_interval
        self.transition_times.append(t)
        self.micro_states.append(x.copy())
        return t, x

    def _make_sigmoid_activation_rate(self, j, J):
        &#34;&#34;&#34;Define a sigmoid activation rate for the `j`th neuron.&#34;&#34;&#34;
        def act(x):
            b = np.dot(self.config.network.W[j], np.real(x)) + self.config.Q[J]
            F_value = self.config.network.populations[J].F(b)
            return self.config.network.alpha[j] * F_value
        return act

    def _make_step_activation_rate(self, j, J):
        &#34;&#34;&#34;Define a step activation rate for the `j`th neuron.&#34;&#34;&#34;
        def act(x):
            b = np.dot(self.config.network.W[j], np.real(x)) + self.config.Q[J]
            if b &lt; self.config.network.theta[j]:
                return 0.
            else:
                return self.config.network.alpha[j]
        return act

    def _make_activation_rate(self, j):
        &#34;&#34;&#34;Define the activation rate function for the `j`th neuron.&#34;&#34;&#34;
        J = 0
        sum_sizes = self.config.network.populations[0].size
        while j &gt; sum_sizes:
            sum_sizes += self.config.network.populations[J+1].size
            J += 1
        if self.activation_rates_shape == &#39;step&#39;:
            return self._make_step_activation_rate(j, J)
        elif self.activation_rates_shape == &#39;sigmoid&#39;:
            return self._make_sigmoid_activation_rate(j, J)
        raise ValueError(f&#39;Unexpected value {self.activation_rates_shape} for &#39;
                         &#39;the shape of the activation rate functions.&#39;)

    def _next_states_and_rates(self, x):
        &#34;&#34;&#34;Get all possible states to which the network can go from `x`.

        Knowing that the network is in state `x`, get all states which are 
        accessible next with the rates associated with each possible transition.

        Returns
        -------
        tuple of array_like
            The next possible states, and the associated transition rates. Both
            arrays are arranged so that the *j*th element of the transition rate
            vector is the rate at which the network can make a transition to the
            state corresponding to the *j*th row of the array of next states.
        &#34;&#34;&#34;
        next_states = np.resize(x, (N := self.config.network.size(), N))
        rates = np.zeros(N)
        for j in range(N):
            next_states[j,j], rates[j] = self._next_state_and_rate(j, x)
        return next_states, rates

    def _next_state_and_rate(self, j, x):
        &#34;&#34;&#34;Get the next state and transition rate of the `j`th neuron.

        Knowing that the network is in state `x`, get the next accessible state
        of `j`th neuron, with the rate at which this neuron will make a 
        transition. 

        Parameters
        ----------
        j : int
            The neuron for which to get the next state and transition rate.
        x : array_like
            The current state of the network.

        Returns
        -------
        tuple of complex and float
            The next state of the `j`th neuron with associated transition rate. 

        Raises
        ------
        ValueError
            If the `j`th neuron is in a non valid state. 
        &#34;&#34;&#34;
        if (z := x[j]) == 0.:
            return 1., self.activation_rates[j](x)
        if z == 1.:
            return 1j, self.config.network.beta[j]
        if z == 1j:
            return 0., self.config.network.gamma[j]
        raise ValueError(&#39;The state of a neuron must always be 0, 1 or the &#39;
                         &#39;imaginary unit.&#39;)

    def _reset_activation_rates(self):
        &#34;&#34;&#34;Reset the activation rate functions.&#34;&#34;&#34;
        self._activation_rates = [self._make_activation_rate(j)
                                  for j in range(self.config.network.size())]

    def _state_length(self):
        &#34;&#34;&#34;Length of the macroscopic states.&#34;&#34;&#34;
        return 2 * len(self.config.network.populations)

    def _update_states(self):
        &#34;&#34;&#34;Update `states` based on `micro_states`.

        Compute the macroscopic states of the network from `micro_states`, and
        update `states` in consequence.
        &#34;&#34;&#34;
        p = len(self.config.network.populations)
        states = np.zeros((len(self.transition_times), 2*p))
        j = 0
        for J, popJ in enumerate(self.config.network.populations):
            states[:,J]   = np.sum(np.real(self.micro_states[:,j:j+popJ.size]), 
                                axis=1) / popJ.size
            states[:,p+J] = np.sum(np.imag(self.micro_states[:,j:j+popJ.size]), 
                                axis=1) / popJ.size
            j += popJ.size
        self._states = states</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="popnet.executors.Executor" href="#popnet.executors.Executor">Executor</a></li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="popnet.executors.ChainSimulator" href="#popnet.executors.ChainSimulator">ChainSimulator</a></li>
<li><a title="popnet.executors.SimpleSimulator" href="#popnet.executors.SimpleSimulator">SimpleSimulator</a></li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="popnet.executors.Simulator.activation_rates"><code class="name">var <span class="ident">activation_rates</span></code></dt>
<dd>
<div class="desc"><p>Activation rates of the neurons.</p>
<p>List of functions representing the activation rates of the network's
neurons. <code>activation_rates[j](x)</code> gives the activation rate of the
<em>j</em>th neuron of the network if the state of the whole network is <code>x</code>.
It cannot be manually set nor deleted.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def activation_rates(self):
    &#34;&#34;&#34;Activation rates of the neurons.

    List of functions representing the activation rates of the network&#39;s
    neurons. `activation_rates[j](x)` gives the activation rate of the
    *j*th neuron of the network if the state of the whole network is `x`.
    It cannot be manually set nor deleted.
    &#34;&#34;&#34;
    return self._activation_rates</code></pre>
</details>
</dd>
<dt id="popnet.executors.Simulator.activation_rates_shape"><code class="name">var <span class="ident">activation_rates_shape</span></code></dt>
<dd>
<div class="desc"><p>Shape of the activation rates.</p>
<p>Shape of the activation rate of a single neuron of the network as a
function of its input. The only valid values are:</p>
<ul>
<li><code>'step'</code>. In that case, a neuron's activation rate is a step
function going from zero to <code><a title="popnet.structures.MicroNetwork.alpha" href="structures.html#popnet.structures.MicroNetwork.alpha">MicroNetwork.alpha</a></code>
at its threshold <code><a title="popnet.structures.MicroNetwork.theta" href="structures.html#popnet.structures.MicroNetwork.theta">MicroNetwork.theta</a></code>.</li>
<li><code>'sigmoid'</code>. In that case, a neuron's activation rate is the
logistic function <code><a title="popnet.structures.Population.F" href="structures.html#popnet.structures.Population.F">Population.F()</a></code> of the population
to which it belongs.</li>
</ul>
<p>It can only be set to one of the above values, and it cannot be
manually deleted.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>After initialization, a change in the value of this property will
only have an effect after a reset of the simulator with
<code><a title="popnet.executors.Simulator.reset" href="#popnet.executors.Simulator.reset">Simulator.reset()</a></code>.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def activation_rates_shape(self):
    &#34;&#34;&#34;Shape of the activation rates.

    Shape of the activation rate of a single neuron of the network as a
    function of its input. The only valid values are:

     - `&#39;step&#39;`. In that case, a neuron&#39;s activation rate is a step
       function going from zero to `popnet.structures.MicroNetwork.alpha`
       at its threshold `popnet.structures.MicroNetwork.theta`.
     - `&#39;sigmoid&#39;`. In that case, a neuron&#39;s activation rate is the
       logistic function `popnet.structures.Population.F` of the population
       to which it belongs.

    It can only be set to one of the above values, and it cannot be
    manually deleted.

    !!! note
        After initialization, a change in the value of this property will
        only have an effect after a reset of the simulator with
        `Simulator.reset`.
    &#34;&#34;&#34;
    return self._activation_rates_shape</code></pre>
</details>
</dd>
<dt id="popnet.executors.Simulator.micro_states"><code class="name">var <span class="ident">micro_states</span></code></dt>
<dd>
<div class="desc"><p>Microscopic state of the network with respect to time.</p>
<p>Microscopic state of the network at each time step in
<code><a title="popnet.executors.Simulator.transition_times" href="#popnet.executors.Simulator.transition_times">Simulator.transition_times</a></code>. It does not contain any relevant data at
initialization or right after a reset, but it is updated during a call
to <code><a title="popnet.executors.Simulator.run" href="#popnet.executors.Executor.run">Executor.run()</a></code>. It cannot be manually set nor deleted.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def micro_states(self):
    &#34;&#34;&#34;Microscopic state of the network with respect to time.

    Microscopic state of the network at each time step in
    `Simulator.transition_times`. It does not contain any relevant data at
    initialization or right after a reset, but it is updated during a call
    to `Simulator.run`. It cannot be manually set nor deleted.
    &#34;&#34;&#34;
    return self._micro_states</code></pre>
</details>
</dd>
<dt id="popnet.executors.Simulator.transition_times"><code class="name">var <span class="ident">transition_times</span></code></dt>
<dd>
<div class="desc"><p>Time.</p>
<p>Times at which transitions have occurred for a given trajectory. Unlike
<code><a title="popnet.executors.Simulator.times" href="#popnet.executors.Executor.times">Simulator.times</a></code>, it is not set according to the configuration used,
but rather updated stochastically during a call to <code><a title="popnet.executors.Simulator.run" href="#popnet.executors.Executor.run">Executor.run()</a></code>. It
does not contain any relevant data at initialization or right after a
reset. It cannot be manually set nor deleted.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def transition_times(self):
    &#34;&#34;&#34;Time.

    Times at which transitions have occurred for a given trajectory. Unlike
    `Simulator.times`, it is not set according to the configuration used,
    but rather updated stochastically during a call to `Simulator.run`. It
    does not contain any relevant data at initialization or right after a
    reset. It cannot be manually set nor deleted.
    &#34;&#34;&#34;
    return self._transition_times</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="popnet.executors.Simulator.calcium_output"><code class="name flex">
<span>def <span class="ident">calcium_output</span></span>(<span>self, indices=None, growth_rate=None, decay_rate=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the calcium concentration in neural cells.</p>
<p>Get the concentration of calcium in neural cells with respect to time. </p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>indices</code></strong> :&ensp;<code>int</code> or <code>array_like</code>, optional</dt>
<dd>Indices of neurons for which to get the calcium concentration.
Defaults to <code>None</code>, in which case the calcium concentration is given
for every neuron of the network.</dd>
<dt><strong><code>growth_rate</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>Initial growth rate of the calcium concentration. It must be
positive. Defaults to <code>None</code>, in which case it is replaced with the
inverse of the configuration's time step
<code><a title="popnet.structures.Configuration.delta" href="structures.html#popnet.structures.Configuration.delta">Configuration.delta</a></code>.</dd>
<dt><strong><code>decay_rate</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>Decay rate of the calcium concentration. It must be positive, and it
should be much smaller than the initial growth rate. Defaults to
<code>None</code>, in which case it is replaced with five percent of the
initial growth rate.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>array_like</code></dt>
<dd>Calcium concentration with respect to time for every requested
neuron, with neurons along the first axis and time along the second.
If a single neuron was requested, it is one-dimensional.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If <code>indices</code> is not a valid list of indices for neurons of the
network.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calcium_output(self, indices=None, growth_rate=None, decay_rate=None):
    &#34;&#34;&#34;Get the calcium concentration in neural cells.

    Get the concentration of calcium in neural cells with respect to time. 

    Parameters
    ----------
    indices : int or array_like, optional
        Indices of neurons for which to get the calcium concentration.
        Defaults to `None`, in which case the calcium concentration is given
        for every neuron of the network.
    growth_rate : float, optional
        Initial growth rate of the calcium concentration. It must be
        positive. Defaults to `None`, in which case it is replaced with the
        inverse of the configuration&#39;s time step
        `popnet.structures.Configuration.delta`.
    decay_rate : float, optional
        Decay rate of the calcium concentration. It must be positive, and it
        should be much smaller than the initial growth rate. Defaults to
        `None`, in which case it is replaced with five percent of the
        initial growth rate.

    Returns
    -------
    array_like
        Calcium concentration with respect to time for every requested
        neuron, with neurons along the first axis and time along the second.
        If a single neuron was requested, it is one-dimensional.

    Raises
    ------
    ValueError
        If `indices` is not a valid list of indices for neurons of the
        network.
    &#34;&#34;&#34;
    if growth_rate is None:
        growth_rate = 1 / self.config.delta
    if decay_rate is None:
        decay_rate = .05 * growth_rate
    if isinstance(indices, int):
        return self._get_calcium_output(indices, growth_rate, decay_rate)
    valid_indices = np.arange(self.config.network.size())
    if indices is None:
        indices = valid_indices
    try:
        valid_indices[indices]
    except IndexError as error:
        raise ValueError(f&#39;{indices} is not a valid list of indices for &#39;
                         &#39;neurons of the network.&#39;) from error
    calcium = np.zeros((N := len(indices), len(self.transition_times)))
    for j in range(N):
        calcium[j,:] = self._get_calcium_output(j, growth_rate, decay_rate)
    return calcium</code></pre>
</details>
</dd>
<dt id="popnet.executors.Simulator.close"><code class="name flex">
<span>def <span class="ident">close</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Delete all data attributes of the simulator.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def close(self):
    &#34;&#34;&#34;Delete all data attributes of the simulator.&#34;&#34;&#34;
    super().close()
    del self._micro_states
    del self._transition_times</code></pre>
</details>
</dd>
<dt id="popnet.executors.Simulator.micro_output"><code class="name flex">
<span>def <span class="ident">micro_output</span></span>(<span>self, fmt='ternary')</span>
</code></dt>
<dd>
<div class="desc"><p>Get the simulation's microscopic output.</p>
<p>Get the microscopic state of the network with respect to time after
a simulation was performed.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>fmt</code></strong> :&ensp;<code>{'binary', 'ternary', 'calcium'}</code>, optional</dt>
<dd>Format of the neurons' states. If <code>'ternary'</code>, a neuron's state can
take the values <code>1</code>, <code>1j</code> or <code>0</code>, associated with the <em>active</em>,
<em>refractory</em> and <em>sensitive</em> states respectively. If <code>'binary'</code>, a
neuron's state can take the values <code>1</code> or <code>0</code>, where <code>1</code> is still
associated with the active state, but <code>0</code> is rather associated with
any non-active state (sensitive or refractory). If <code>'calcium'</code>,
the returned output is the default given by
<code><a title="popnet.executors.Simulator.calcium_output" href="#popnet.executors.Simulator.calcium_output">Simulator.calcium_output()</a></code>. Defaults to <code>'ternary'</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>array_like</code></dt>
<dd>Microscopic state of the network with respect to time.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If <code>fmt</code> is passed an unexpected value.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def micro_output(self, fmt=&#39;ternary&#39;):
    &#34;&#34;&#34;Get the simulation&#39;s microscopic output.
    
    Get the microscopic state of the network with respect to time after
    a simulation was performed.

    Parameters
    ----------
    fmt : {&#39;binary&#39;, &#39;ternary&#39;, &#39;calcium&#39;}, optional
        Format of the neurons&#39; states. If `&#39;ternary&#39;`, a neuron&#39;s state can
        take the values `1`, `1j` or `0`, associated with the *active*,
        *refractory* and *sensitive* states respectively. If `&#39;binary&#39;`, a
        neuron&#39;s state can take the values `1` or `0`, where `1` is still
        associated with the active state, but `0` is rather associated with
        any non-active state (sensitive or refractory). If `&#39;calcium&#39;`,
        the returned output is the default given by
        `Simulator.calcium_output`. Defaults to `&#39;ternary&#39;`.

    Returns
    -------
    array_like
        Microscopic state of the network with respect to time.

    Raises
    ------
    ValueError
        If `fmt` is passed an unexpected value.
    &#34;&#34;&#34;
    self._check_if_run()
    if fmt == &#39;ternary&#39;:
        return self.micro_states
    if fmt == &#39;binary&#39;:
        return np.real(self.micro_states)
    if fmt == &#39;calcium&#39;:
        return self.calcium_output()
    raise ValueError(f&#39;Unexpected format {fmt} for microscopic states. Valid&#39;
                     &#39; values are \&#39;ternary\&#39;, \&#39;binary\&#39; and \&#39;calcium\&#39;.&#39;)</code></pre>
</details>
</dd>
<dt id="popnet.executors.Simulator.reset"><code class="name flex">
<span>def <span class="ident">reset</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Reset the simulator.</p>
<p>Reset the simulator to run it again. It extends the base class method
by also resetting the arrays <code><a title="popnet.executors.Simulator.states" href="#popnet.executors.Executor.states">Simulator.states</a></code>,
<code><a title="popnet.executors.Simulator.micro_states" href="#popnet.executors.Simulator.micro_states">Simulator.micro_states</a></code> and <code><a title="popnet.executors.Simulator.transition_times" href="#popnet.executors.Simulator.transition_times">Simulator.transition_times</a></code>, by
resetting the activation rate functions, and by resetting the
microscopic initial state to be used in the simulation from the
configuration.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset(self):
    &#34;&#34;&#34;Reset the simulator.

    Reset the simulator to run it again. It extends the base class method
    by also resetting the arrays `Simulator.states`,
    `Simulator.micro_states` and `Simulator.transition_times`, by
    resetting the activation rate functions, and by resetting the
    microscopic initial state to be used in the simulation from the
    configuration.
    &#34;&#34;&#34;
    super().reset()
    self._states = None
    self._transition_times = [self.config.initial_time]
    self._micro_states = [self.config.micro_initial_state.copy()]
    self._reset_activation_rates()</code></pre>
</details>
</dd>
<dt id="popnet.executors.Simulator.single_run"><code class="name flex">
<span>def <span class="ident">single_run</span></span>(<span>self, rng, do_step, iterate)</span>
</code></dt>
<dd>
<div class="desc"><p>Run a single simulation.</p>
<p>Run a simulation to obtain a possible trajectory of the stochastic
process which describes the evolution of the network. To obtain this
trajectory, the Doob&ndash;Gillespie algorithm is used either with the
direct method or with the first reaction method. See the
<a href="#simulator-single-run-notes">Notes</a> section below for more details
about the algorithm.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The recommended way to perform simulations of the stochastic process
is <em>not</em> to use this method, but rather to use <code><a title="popnet.executors.SimpleSimulator.run" href="#popnet.executors.SimpleSimulator.run">SimpleSimulator.run()</a></code>
or <code><a title="popnet.executors.ChainSimulator.run" href="#popnet.executors.ChainSimulator.run">ChainSimulator.run()</a></code>, which both use it internally.</p>
</div>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>rng</code></strong> :&ensp;<code>numpy.random.Generator</code></dt>
<dd>A random number generator.</dd>
<dt><strong><code>do_step</code></strong> :&ensp;<code>callable</code></dt>
<dd>Dictates how to do the Monte Carlo step of the Doob&ndash;Gillespie
algorithm. It is a function to be passed to <code>iterate</code>. It expects
as inputs, in order: <code>rng</code>, the current time <code>t</code>, an array of the
next possible network states, and an array of the corresponding
transition rates. It should return the index of the next network
state and the time interval between <code>t</code> and the next transition.</dd>
<dt><strong><code>iterate</code></strong> :&ensp;<code>callable</code></dt>
<dd>Dictates how a complete iteration of the simulation is performed.
This includes the Monte Carlo step as well as all other tasks that
should be done at each time step. It expects as inputs, in order:
<code>do_step</code>, <code>rng</code>, <code>t</code> and <code>x</code>, where <code>t</code> and <code>x</code> are the current
time and network state. It should return the next time and network
state.</dd>
</dl>
<h2 id="simulator-single-run-notes">Notes</h2>
<p>From the microscopic point of view, the evolution of the state of the
whole network is described by a stochastic process. The simulation run
by this method outputs a possible trajectory of this stochastic process,
using the Doob&ndash;Gillespie algorithm, based on results of Doob [1,2] and
popularized by Gillespie in [3]. To pass from a state to another, the
idea is first to find all of the states to which the network can go
from the current one, with the corresponding transition rates. This
information is in fact sufficient to determine the distribution of the
time at which the next transition occurs and which one will occur.</p>
<p>In [3], Gillespie introduces two methods, called the <em>direct</em> and
<em>first reaction</em> methods respectively, to choose the time interval until
the next transition and the next state of the system.</p>
<ul>
<li>
<p><strong>Direct method.</strong> First, the total transition rate out of the
current state is computed, and a time interval until the next
transition is taken randomly knowing that it is exponentially
distributed with parameter equal to this total out rate. Then a next
state is chosen randomly knowing that the probability of going to a
given other state is proportional to the corresponding transition
rate.</p>
</li>
<li>
<p><strong>First reaction method.</strong> For every possible next state, a time at
which the corresponding transition could occur is randomly generated,
knowing that this time is exponentially distributed with parameter
equal to the transition rate. The transition that should occur first
is chosen, and the state is updated accordingly.</p>
</li>
</ul>
<h2 id="references">References</h2>
<ol class="references">
<li>Doob, J. L. “Topics in the Theory of Markoff Chains.” <em>Transactions
of the American Mathematical Society</em> <strong>52</strong>, 37&ndash;64 (1942).
doi: <a href="https://doi.org/10.2307/1990152">10.2307/1990152</a>.</li>
<li>Doob, J. L. “Markoff Chains&ndash;Denumerable Case.” <em>Transactions of the
American Mathematical Society</em> <strong>58</strong>, 455&ndash;473 (1945).
doi: <a href="https://doi.org/10.2307/1990339">10.2307/1990339</a>.</li>
<li>Gillespie, D. T. “A General Method for Numerically Simulating the
Stochastic Time Evolution of Coupled Chemical Reactions.” <em>Journal
of Computational Physics</em> <strong>22</strong>, 403&ndash;434 (1976). doi:
<a href="https://doi.org/10.1016/0021-9991(76)90041-3">10.1016/0021-9991(76)90041-3</a>.</li>
</ol></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def single_run(self, rng, do_step, iterate):
    &#34;&#34;&#34;Run a single simulation.

    Run a simulation to obtain a possible trajectory of the stochastic
    process which describes the evolution of the network. To obtain this
    trajectory, the Doob--Gillespie algorithm is used either with the
    direct method or with the first reaction method. See the
    [Notes](#simulator-single-run-notes) section below for more details
    about the algorithm.

    !!! note
        The recommended way to perform simulations of the stochastic process
        is *not* to use this method, but rather to use `SimpleSimulator.run`
        or `ChainSimulator.run`, which both use it internally.

    Parameters
    ----------
    rng : numpy.random.Generator
        A random number generator.
    do_step : callable
        Dictates how to do the Monte Carlo step of the Doob--Gillespie
        algorithm. It is a function to be passed to `iterate`. It expects
        as inputs, in order: `rng`, the current time `t`, an array of the
        next possible network states, and an array of the corresponding
        transition rates. It should return the index of the next network
        state and the time interval between `t` and the next transition.
    iterate : callable
        Dictates how a complete iteration of the simulation is performed.
        This includes the Monte Carlo step as well as all other tasks that
        should be done at each time step. It expects as inputs, in order:
        `do_step`, `rng`, `t` and `x`, where `t` and `x` are the current
        time and network state. It should return the next time and network
        state.

    Notes {#simulator-single-run-notes}
    -----
    From the microscopic point of view, the evolution of the state of the
    whole network is described by a stochastic process. The simulation run
    by this method outputs a possible trajectory of this stochastic process,
    using the Doob--Gillespie algorithm, based on results of Doob [1,2] and
    popularized by Gillespie in [3]. To pass from a state to another, the
    idea is first to find all of the states to which the network can go
    from the current one, with the corresponding transition rates. This
    information is in fact sufficient to determine the distribution of the
    time at which the next transition occurs and which one will occur.

    In [3], Gillespie introduces two methods, called the *direct* and
    *first reaction* methods respectively, to choose the time interval until
    the next transition and the next state of the system.

     - **Direct method.** First, the total transition rate out of the
       current state is computed, and a time interval until the next
       transition is taken randomly knowing that it is exponentially
       distributed with parameter equal to this total out rate. Then a next
       state is chosen randomly knowing that the probability of going to a
       given other state is proportional to the corresponding transition
       rate.

     - **First reaction method.** For every possible next state, a time at
       which the corresponding transition could occur is randomly generated,
       knowing that this time is exponentially distributed with parameter
       equal to the transition rate. The transition that should occur first
       is chosen, and the state is updated accordingly.

    References
    ----------
     1. Doob, J. L. “Topics in the Theory of Markoff Chains.” *Transactions
        of the American Mathematical Society* **52**, 37--64 (1942).
        doi: [10.2307/1990152](https://doi.org/10.2307/1990152).
     2. Doob, J. L. “Markoff Chains--Denumerable Case.” *Transactions of the
        American Mathematical Society* **58**, 455--473 (1945).
        doi: [10.2307/1990339](https://doi.org/10.2307/1990339).
     3. Gillespie, D. T. “A General Method for Numerically Simulating the
        Stochastic Time Evolution of Coupled Chemical Reactions.” *Journal
        of Computational Physics* **22**, 403--434 (1976). doi:
        [10.1016/0021-9991(76)90041-3](
        https://doi.org/10.1016/0021-9991(76)90041-3).
    &#34;&#34;&#34;
    t = self.transition_times[0]
    x = self.micro_states[0]
    while t &lt; self.config.final_time:
        t, x = iterate(do_step, rng, t, x)
    self._micro_states = np.array(self.micro_states)
    self._transition_times = np.array(self.transition_times)
    self._update_states()</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="popnet.executors.Executor" href="#popnet.executors.Executor">Executor</a></b></code>:
<ul class="hlist">
<li><code><a title="popnet.executors.Executor.config" href="#popnet.executors.Executor.config">config</a></code></li>
<li><code><a title="popnet.executors.Executor.output" href="#popnet.executors.Executor.output">output</a></code></li>
<li><code><a title="popnet.executors.Executor.run" href="#popnet.executors.Executor.run">run</a></code></li>
<li><code><a title="popnet.executors.Executor.save_output" href="#popnet.executors.Executor.save_output">save_output</a></code></li>
<li><code><a title="popnet.executors.Executor.states" href="#popnet.executors.Executor.states">states</a></code></li>
<li><code><a title="popnet.executors.Executor.success" href="#popnet.executors.Executor.success">success</a></code></li>
<li><code><a title="popnet.executors.Executor.times" href="#popnet.executors.Executor.times">times</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul>
<li><a href="#classes-and-hierarchy">Classes and hierarchy</a></li>
</ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="popnet" href="index.html">popnet</a></code></li>
</ul>
</li>
<li><h3><a href="#header-variables">Global variables</a></h3>
<ul class="">
<li><code><a title="popnet.executors.OUTPUT_TYPES" href="#popnet.executors.OUTPUT_TYPES">OUTPUT_TYPES</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="popnet.executors.get_integrator" href="#popnet.executors.get_integrator">get_integrator</a></code></li>
<li><code><a title="popnet.executors.get_simulator" href="#popnet.executors.get_simulator">get_simulator</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="popnet.executors.ChainSimulator" href="#popnet.executors.ChainSimulator">ChainSimulator</a></code></h4>
<ul class="">
<li><code><a title="popnet.executors.ChainSimulator.reset" href="#popnet.executors.ChainSimulator.reset">reset</a></code></li>
<li><code><a title="popnet.executors.ChainSimulator.run" href="#popnet.executors.ChainSimulator.run">run</a></code></li>
<li><code><a title="popnet.executors.ChainSimulator.samples" href="#popnet.executors.ChainSimulator.samples">samples</a></code></li>
<li><code><a title="popnet.executors.ChainSimulator.save_output" href="#popnet.executors.ChainSimulator.save_output">save_output</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="popnet.executors.Executor" href="#popnet.executors.Executor">Executor</a></code></h4>
<ul class="two-column">
<li><code><a title="popnet.executors.Executor.close" href="#popnet.executors.Executor.close">close</a></code></li>
<li><code><a title="popnet.executors.Executor.config" href="#popnet.executors.Executor.config">config</a></code></li>
<li><code><a title="popnet.executors.Executor.output" href="#popnet.executors.Executor.output">output</a></code></li>
<li><code><a title="popnet.executors.Executor.reset" href="#popnet.executors.Executor.reset">reset</a></code></li>
<li><code><a title="popnet.executors.Executor.run" href="#popnet.executors.Executor.run">run</a></code></li>
<li><code><a title="popnet.executors.Executor.save_output" href="#popnet.executors.Executor.save_output">save_output</a></code></li>
<li><code><a title="popnet.executors.Executor.states" href="#popnet.executors.Executor.states">states</a></code></li>
<li><code><a title="popnet.executors.Executor.success" href="#popnet.executors.Executor.success">success</a></code></li>
<li><code><a title="popnet.executors.Executor.times" href="#popnet.executors.Executor.times">times</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="popnet.executors.Integrator" href="#popnet.executors.Integrator">Integrator</a></code></h4>
<ul class="">
<li><code><a title="popnet.executors.Integrator.reset" href="#popnet.executors.Integrator.reset">reset</a></code></li>
<li><code><a title="popnet.executors.Integrator.run" href="#popnet.executors.Integrator.run">run</a></code></li>
<li><code><a title="popnet.executors.Integrator.system" href="#popnet.executors.Integrator.system">system</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="popnet.executors.LyapunovExponentsIntegrator" href="#popnet.executors.LyapunovExponentsIntegrator">LyapunovExponentsIntegrator</a></code></h4>
<ul class="">
<li><code><a title="popnet.executors.LyapunovExponentsIntegrator.close" href="#popnet.executors.LyapunovExponentsIntegrator.close">close</a></code></li>
<li><code><a title="popnet.executors.LyapunovExponentsIntegrator.exponents" href="#popnet.executors.LyapunovExponentsIntegrator.exponents">exponents</a></code></li>
<li><code><a title="popnet.executors.LyapunovExponentsIntegrator.output" href="#popnet.executors.LyapunovExponentsIntegrator.output">output</a></code></li>
<li><code><a title="popnet.executors.LyapunovExponentsIntegrator.reset" href="#popnet.executors.LyapunovExponentsIntegrator.reset">reset</a></code></li>
<li><code><a title="popnet.executors.LyapunovExponentsIntegrator.run" href="#popnet.executors.LyapunovExponentsIntegrator.run">run</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="popnet.executors.SimpleSimulator" href="#popnet.executors.SimpleSimulator">SimpleSimulator</a></code></h4>
<ul class="">
<li><code><a title="popnet.executors.SimpleSimulator.run" href="#popnet.executors.SimpleSimulator.run">run</a></code></li>
<li><code><a title="popnet.executors.SimpleSimulator.save_output" href="#popnet.executors.SimpleSimulator.save_output">save_output</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="popnet.executors.Simulator" href="#popnet.executors.Simulator">Simulator</a></code></h4>
<ul class="">
<li><code><a title="popnet.executors.Simulator.activation_rates" href="#popnet.executors.Simulator.activation_rates">activation_rates</a></code></li>
<li><code><a title="popnet.executors.Simulator.activation_rates_shape" href="#popnet.executors.Simulator.activation_rates_shape">activation_rates_shape</a></code></li>
<li><code><a title="popnet.executors.Simulator.calcium_output" href="#popnet.executors.Simulator.calcium_output">calcium_output</a></code></li>
<li><code><a title="popnet.executors.Simulator.close" href="#popnet.executors.Simulator.close">close</a></code></li>
<li><code><a title="popnet.executors.Simulator.micro_output" href="#popnet.executors.Simulator.micro_output">micro_output</a></code></li>
<li><code><a title="popnet.executors.Simulator.micro_states" href="#popnet.executors.Simulator.micro_states">micro_states</a></code></li>
<li><code><a title="popnet.executors.Simulator.reset" href="#popnet.executors.Simulator.reset">reset</a></code></li>
<li><code><a title="popnet.executors.Simulator.single_run" href="#popnet.executors.Simulator.single_run">single_run</a></code></li>
<li><code><a title="popnet.executors.Simulator.transition_times" href="#popnet.executors.Simulator.transition_times">transition_times</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.1</a>.</p>
</footer>
</body>
</html>